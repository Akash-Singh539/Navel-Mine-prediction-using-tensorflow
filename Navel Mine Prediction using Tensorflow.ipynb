{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the required Libraries\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from pandas import DataFrame, read_csv\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_dataset():\n",
    "    df = pd.read_csv(\"C:/Users/18579/Desktop/data/all_data.csv\")\n",
    "    # X and y are np arrays\n",
    "    X = df[df.columns[0:60]].values\n",
    "    y = df[df.columns[60]]\n",
    "    \n",
    "    # Encode the dependent variable\n",
    "    encoder = LabelEncoder()\n",
    "    encoder.fit(y)\n",
    "    #encoder.classes_\n",
    "    y = encoder.transform(y)\n",
    "    Y = one_hot_encode(y)\n",
    "    return X,Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encode(y):\n",
    "    n_labels = len(y)\n",
    "    n_unique_labels = len(np.unique(y))\n",
    "    one_hot_encode = np.zeros((n_labels,n_unique_labels))\n",
    "    one_hot_encode[np.arange(n_labels),y] = 1\n",
    "    return one_hot_encode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multilayer_perceptron(x, weights, biases):\n",
    "    \n",
    "    # Hidden layer with sigmoid activated\n",
    "    layer_1 = tf.add(tf.matmul(x,weights['h1']), biases['b1'])\n",
    "    layer_1 = tf.nn.sigmoid(layer_1)\n",
    "    \n",
    "    # Hidden layer with sigmoid activated\n",
    "    layer_2 = tf.add(tf.matmul(layer_1,weights['h2']), biases['b2'])\n",
    "    layer_2 = tf.nn.sigmoid(layer_2)\n",
    "    \n",
    "    # Hidden layer with sigmoid activated\n",
    "    layer_3 = tf.add(tf.matmul(layer_2,weights['h3']), biases['b3'])\n",
    "    layer_3 = tf.nn.sigmoid(layer_3)\n",
    "    \n",
    "    # Hidden layer with RELU activated\n",
    "    layer_4 = tf.add(tf.matmul(layer_3,weights['h4']), biases['b4'])\n",
    "    layer_4 = tf.nn.relu(layer_4)\n",
    "    \n",
    "    # Output layer with linear activation\n",
    "    out_layer = tf.matmul(layer_4, weights['out']+biases['out'])\n",
    "    return out_layer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the dataset\n",
    "X, Y = read_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shuffle the dataset to mix up the rows\n",
    "X, Y = shuffle(X, Y, random_state = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the dataset into train and test part\n",
    "train_x, test_x, train_y, test_y = train_test_split(X, Y, test_size=0.2, random_state=415)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(165, 60)\n",
      "(165, 2)\n",
      "(42, 60)\n",
      "(42, 2)\n"
     ]
    }
   ],
   "source": [
    "# Inspect the shape of the training and testing\n",
    "print(train_x.shape)\n",
    "print(train_y.shape)\n",
    "print(test_x.shape)\n",
    "print(test_y.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_dim 60\n"
     ]
    }
   ],
   "source": [
    "# Define the important parametrs and variables to work with the tensors\n",
    "learning_rate = 0.02\n",
    "training_epochs = 1000\n",
    "cost_history = np.empty(shape = [1], dtype=float)\n",
    "n_dim = X.shape[1]\n",
    "print(\"n_dim\",n_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_class = 2\n",
    "model_path = \"C:/Users/18579/Desktop/data/model\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the number of hidden layers and number of neurons for each layer\n",
    "n_hidden_1 = 60\n",
    "n_hidden_2 = 70\n",
    "n_hidden_3 = 70\n",
    "n_hidden_4 = 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.float32,[None,n_dim]) # None means any value\n",
    "W = tf.Variable(tf.zeros([n_dim,n_class]))\n",
    "b = tf.Variable(tf.zeros([n_class]))\n",
    "y_true = tf.placeholder(tf.float32,[None,n_class])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = {\n",
    "    'h1': tf.Variable(tf.truncated_normal([n_dim,n_hidden_1])),\n",
    "    'h2': tf.Variable(tf.truncated_normal([n_hidden_1,n_hidden_2])),\n",
    "    'h3': tf.Variable(tf.truncated_normal([n_hidden_2,n_hidden_3])),\n",
    "    'h4': tf.Variable(tf.truncated_normal([n_hidden_3,n_hidden_4])),\n",
    "    'out': tf.Variable(tf.truncated_normal([n_hidden_4,n_class]))\n",
    "}\n",
    "\n",
    "biases = {\n",
    "    'b1': tf.Variable(tf.truncated_normal([n_hidden_1])),\n",
    "    'b2': tf.Variable(tf.truncated_normal([n_hidden_2])),\n",
    "    'b3': tf.Variable(tf.truncated_normal([n_hidden_3])),\n",
    "    'b4': tf.Variable(tf.truncated_normal([n_hidden_4])),\n",
    "    'out': tf.Variable(tf.truncated_normal([n_class]))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize all the variables\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saver object to save our model\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call your model defined\n",
    "y = multilayer_perceptron(x, weights, biases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0831 15:24:23.143898 12948 deprecation.py:323] From <ipython-input-57-ba49a8a1609b>:2: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Define the cost function and optimizer\n",
    "cost_function = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=y, labels=y_true))\n",
    "training_step = tf.train.GradientDescentOptimizer(learning_rate).minimize(cost_function)\n",
    "\n",
    "sess = tf.Session()\n",
    "sess.run(init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**\n",
      "(165, 60)\n",
      "(165, 2)\n",
      "(42, 60)\n",
      "(42, 2)\n"
     ]
    }
   ],
   "source": [
    "# Calculate the cost and accuracy for each epoch\n",
    "\n",
    "mse_history = []\n",
    "accuracy_history = []\n",
    "print(\"**\")\n",
    "print(train_x.shape)\n",
    "print(train_y.shape)\n",
    "print(test_x.shape)\n",
    "print(test_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  0  -  cost: 118.05241  -MSE: 21372.425003772398  -Train Accuracy:  0.54545456\n",
      "epoch:  1  -  cost: 4.818637  -MSE: 2855.348740675813  -Train Accuracy:  0.54545456\n",
      "epoch:  2  -  cost: 63.930485  -MSE: 6064.228398069936  -Train Accuracy:  0.45454547\n",
      "epoch:  3  -  cost: 12.591949  -MSE: 2106.2248626365526  -Train Accuracy:  0.54545456\n",
      "epoch:  4  -  cost: 30.910059  -MSE: 2431.4816693915245  -Train Accuracy:  0.45454547\n",
      "epoch:  5  -  cost: 12.799624  -MSE: 1594.8125275379346  -Train Accuracy:  0.54545456\n",
      "epoch:  6  -  cost: 16.89283  -MSE: 1401.1995387395746  -Train Accuracy:  0.45454547\n",
      "epoch:  7  -  cost: 11.742056  -MSE: 1209.8005834663259  -Train Accuracy:  0.54545456\n",
      "epoch:  8  -  cost: 8.290538  -MSE: 928.2610883974414  -Train Accuracy:  0.45454547\n",
      "epoch:  9  -  cost: 11.815238  -MSE: 1002.2394359431762  -Train Accuracy:  0.54545456\n",
      "epoch:  10  -  cost: 2.7838776  -MSE: 691.6013343569184  -Train Accuracy:  0.45454547\n",
      "epoch:  11  -  cost: 11.649957  -MSE: 855.0560154717135  -Train Accuracy:  0.54545456\n",
      "epoch:  12  -  cost: 0.73806876  -MSE: 561.7224410136645  -Train Accuracy:  0.6363636\n",
      "epoch:  13  -  cost: 1.2155229  -MSE: 564.8707747076097  -Train Accuracy:  0.57575756\n",
      "epoch:  14  -  cost: 7.289984  -MSE: 618.5606703538099  -Train Accuracy:  0.45454547\n",
      "epoch:  15  -  cost: 5.1389565  -MSE: 518.6841890334782  -Train Accuracy:  0.54545456\n",
      "epoch:  16  -  cost: 3.1219134  -MSE: 452.57978372363294  -Train Accuracy:  0.45454547\n",
      "epoch:  17  -  cost: 5.77311  -MSE: 460.6361809435245  -Train Accuracy:  0.54545456\n",
      "epoch:  18  -  cost: 1.1157044  -MSE: 385.13241653569924  -Train Accuracy:  0.44848484\n",
      "epoch:  19  -  cost: 4.120247  -MSE: 392.6838896529875  -Train Accuracy:  0.54545456\n",
      "epoch:  20  -  cost: 2.02407  -MSE: 359.3229062199415  -Train Accuracy:  0.45454547\n",
      "epoch:  21  -  cost: 4.584942  -MSE: 353.5846766767852  -Train Accuracy:  0.54545456\n",
      "epoch:  22  -  cost: 0.8697679  -MSE: 307.72109292591597  -Train Accuracy:  0.5212121\n",
      "epoch:  23  -  cost: 2.3073015  -MSE: 307.1407511325747  -Train Accuracy:  0.54545456\n",
      "epoch:  24  -  cost: 2.6650662  -MSE: 310.9278249798083  -Train Accuracy:  0.45454547\n",
      "epoch:  25  -  cost: 3.2045395  -MSE: 278.0436281636811  -Train Accuracy:  0.54545456\n",
      "epoch:  26  -  cost: 0.958347  -MSE: 255.5882295240521  -Train Accuracy:  0.47272727\n",
      "epoch:  27  -  cost: 1.9263836  -MSE: 252.0727945515237  -Train Accuracy:  0.54545456\n",
      "epoch:  28  -  cost: 1.7095879  -MSE: 254.35009259380968  -Train Accuracy:  0.45454547\n",
      "epoch:  29  -  cost: 2.412252  -MSE: 236.51432708890158  -Train Accuracy:  0.54545456\n",
      "epoch:  30  -  cost: 0.990345  -MSE: 227.06729690276882  -Train Accuracy:  0.47272727\n",
      "epoch:  31  -  cost: 1.5662681  -MSE: 219.58690271622686  -Train Accuracy:  0.54545456\n",
      "epoch:  32  -  cost: 1.3833318  -MSE: 224.23706271432266  -Train Accuracy:  0.45454547\n",
      "epoch:  33  -  cost: 1.8238059  -MSE: 206.60604820727397  -Train Accuracy:  0.54545456\n",
      "epoch:  34  -  cost: 1.0187706  -MSE: 204.40770941304694  -Train Accuracy:  0.4848485\n",
      "epoch:  35  -  cost: 1.305618  -MSE: 195.22727813636325  -Train Accuracy:  0.56363636\n",
      "epoch:  36  -  cost: 1.1618993  -MSE: 202.13372061796144  -Train Accuracy:  0.47272727\n",
      "epoch:  37  -  cost: 1.440718  -MSE: 185.90682516064655  -Train Accuracy:  0.55151516\n",
      "epoch:  38  -  cost: 0.96955854  -MSE: 188.5693666826254  -Train Accuracy:  0.4969697\n",
      "epoch:  39  -  cost: 1.107095  -MSE: 178.33086020588175  -Train Accuracy:  0.56969696\n",
      "epoch:  40  -  cost: 0.9877433  -MSE: 185.32219071908096  -Train Accuracy:  0.5090909\n",
      "epoch:  41  -  cost: 1.1401572  -MSE: 171.6481912266814  -Train Accuracy:  0.56969696\n",
      "epoch:  42  -  cost: 0.91518515  -MSE: 177.6983169293881  -Train Accuracy:  0.5151515\n",
      "epoch:  43  -  cost: 1.01129  -MSE: 166.0004666814684  -Train Accuracy:  0.5939394\n",
      "epoch:  44  -  cost: 0.8643697  -MSE: 172.69278467240943  -Train Accuracy:  0.53939396\n",
      "epoch:  45  -  cost: 0.9394233  -MSE: 161.31708058466316  -Train Accuracy:  0.6060606\n",
      "epoch:  46  -  cost: 0.8209419  -MSE: 168.1246055306359  -Train Accuracy:  0.55151516\n",
      "epoch:  47  -  cost: 0.8879178  -MSE: 157.46475112277753  -Train Accuracy:  0.6121212\n",
      "epoch:  48  -  cost: 0.78354853  -MSE: 163.7466579813215  -Train Accuracy:  0.55757576\n",
      "epoch:  49  -  cost: 0.8263557  -MSE: 154.14469441084125  -Train Accuracy:  0.6363636\n",
      "epoch:  50  -  cost: 0.75550926  -MSE: 161.03205227490938  -Train Accuracy:  0.57575756\n",
      "epoch:  51  -  cost: 0.80563474  -MSE: 151.1703438449402  -Train Accuracy:  0.6424242\n",
      "epoch:  52  -  cost: 0.72979313  -MSE: 157.7484714395691  -Train Accuracy:  0.6\n",
      "epoch:  53  -  cost: 0.7719325  -MSE: 148.63009903668177  -Train Accuracy:  0.6424242\n",
      "epoch:  54  -  cost: 0.6994307  -MSE: 154.98201926625077  -Train Accuracy:  0.6121212\n",
      "epoch:  55  -  cost: 0.73604083  -MSE: 146.46641431853502  -Train Accuracy:  0.6484848\n",
      "epoch:  56  -  cost: 0.6705621  -MSE: 152.4345350360287  -Train Accuracy:  0.630303\n",
      "epoch:  57  -  cost: 0.7020863  -MSE: 144.64050528040156  -Train Accuracy:  0.6606061\n",
      "epoch:  58  -  cost: 0.6536191  -MSE: 150.75396280324316  -Train Accuracy:  0.6545454\n",
      "epoch:  59  -  cost: 0.6933808  -MSE: 142.84927069440892  -Train Accuracy:  0.6606061\n",
      "epoch:  60  -  cost: 0.6413294  -MSE: 148.83130251290766  -Train Accuracy:  0.6545454\n",
      "epoch:  61  -  cost: 0.67031896  -MSE: 141.4579171098247  -Train Accuracy:  0.6727273\n",
      "epoch:  62  -  cost: 0.6290732  -MSE: 147.43494899129223  -Train Accuracy:  0.6606061\n",
      "epoch:  63  -  cost: 0.6613651  -MSE: 140.00261485664646  -Train Accuracy:  0.6727273\n",
      "epoch:  64  -  cost: 0.62024164  -MSE: 145.7199357496433  -Train Accuracy:  0.6606061\n",
      "epoch:  65  -  cost: 0.6468499  -MSE: 138.66743421951398  -Train Accuracy:  0.6787879\n",
      "epoch:  66  -  cost: 0.6077944  -MSE: 144.32967229428337  -Train Accuracy:  0.6666667\n",
      "epoch:  67  -  cost: 0.6272897  -MSE: 137.64982008710692  -Train Accuracy:  0.6909091\n",
      "epoch:  68  -  cost: 0.59356  -MSE: 143.16773413519218  -Train Accuracy:  0.6848485\n",
      "epoch:  69  -  cost: 0.61001414  -MSE: 136.72130602500908  -Train Accuracy:  0.7030303\n",
      "epoch:  70  -  cost: 0.5767945  -MSE: 141.93372272106703  -Train Accuracy:  0.6969697\n",
      "epoch:  71  -  cost: 0.5846084  -MSE: 136.1821989243874  -Train Accuracy:  0.7151515\n",
      "epoch:  72  -  cost: 0.55986893  -MSE: 141.09226023208333  -Train Accuracy:  0.7090909\n",
      "epoch:  73  -  cost: 0.568279  -MSE: 135.62806743646038  -Train Accuracy:  0.72121215\n",
      "epoch:  74  -  cost: 0.545948  -MSE: 140.34789614270755  -Train Accuracy:  0.74545455\n",
      "epoch:  75  -  cost: 0.55122966  -MSE: 135.26575572456773  -Train Accuracy:  0.72727275\n",
      "epoch:  76  -  cost: 0.5329067  -MSE: 139.67955012932057  -Train Accuracy:  0.76363635\n",
      "epoch:  77  -  cost: 0.5367968  -MSE: 135.1206653521727  -Train Accuracy:  0.73333335\n",
      "epoch:  78  -  cost: 0.525258  -MSE: 139.65649308703868  -Train Accuracy:  0.75757575\n",
      "epoch:  79  -  cost: 0.53527176  -MSE: 134.54893690891055  -Train Accuracy:  0.73333335\n",
      "epoch:  80  -  cost: 0.52220863  -MSE: 138.84975858548236  -Train Accuracy:  0.76363635\n",
      "epoch:  81  -  cost: 0.5278398  -MSE: 134.2294126223773  -Train Accuracy:  0.73333335\n",
      "epoch:  82  -  cost: 0.5141334  -MSE: 138.41876950140576  -Train Accuracy:  0.76363635\n",
      "epoch:  83  -  cost: 0.51764405  -MSE: 133.8947469961251  -Train Accuracy:  0.73333335\n",
      "epoch:  84  -  cost: 0.50643486  -MSE: 138.05325704723103  -Train Accuracy:  0.76363635\n",
      "epoch:  85  -  cost: 0.5108159  -MSE: 133.64496519659258  -Train Accuracy:  0.73333335\n",
      "epoch:  86  -  cost: 0.5009094  -MSE: 137.79152003922974  -Train Accuracy:  0.76969695\n",
      "epoch:  87  -  cost: 0.50424963  -MSE: 133.46478172439632  -Train Accuracy:  0.74545455\n",
      "epoch:  88  -  cost: 0.49409476  -MSE: 137.420221857427  -Train Accuracy:  0.76969695\n",
      "epoch:  89  -  cost: 0.4982843  -MSE: 133.32970386268798  -Train Accuracy:  0.74545455\n",
      "epoch:  90  -  cost: 0.48865116  -MSE: 137.14602568523844  -Train Accuracy:  0.76969695\n",
      "epoch:  91  -  cost: 0.49117145  -MSE: 133.18989150912233  -Train Accuracy:  0.74545455\n",
      "epoch:  92  -  cost: 0.4810479  -MSE: 136.7426758786825  -Train Accuracy:  0.77575755\n",
      "epoch:  93  -  cost: 0.4812634  -MSE: 133.24165136205556  -Train Accuracy:  0.76363635\n",
      "epoch:  94  -  cost: 0.4727817  -MSE: 136.52809434165815  -Train Accuracy:  0.7878788\n",
      "epoch:  95  -  cost: 0.47359744  -MSE: 133.20661846863558  -Train Accuracy:  0.76969695\n",
      "epoch:  96  -  cost: 0.46469647  -MSE: 136.20916224412588  -Train Accuracy:  0.8\n",
      "epoch:  97  -  cost: 0.46568808  -MSE: 133.37142984888928  -Train Accuracy:  0.76363635\n",
      "epoch:  98  -  cost: 0.4609021  -MSE: 136.17344983701014  -Train Accuracy:  0.8\n",
      "epoch:  99  -  cost: 0.46281198  -MSE: 133.33057612648173  -Train Accuracy:  0.76363635\n",
      "epoch:  100  -  cost: 0.45710894  -MSE: 136.05297743191525  -Train Accuracy:  0.8\n",
      "epoch:  101  -  cost: 0.4596917  -MSE: 133.2551992267832  -Train Accuracy:  0.76363635\n",
      "epoch:  102  -  cost: 0.45447809  -MSE: 135.93097404719109  -Train Accuracy:  0.8\n",
      "epoch:  103  -  cost: 0.45744196  -MSE: 133.21104000127102  -Train Accuracy:  0.76363635\n",
      "epoch:  104  -  cost: 0.4523218  -MSE: 135.94296223584323  -Train Accuracy:  0.8121212\n",
      "epoch:  105  -  cost: 0.45632714  -MSE: 133.13334098894106  -Train Accuracy:  0.76363635\n",
      "epoch:  106  -  cost: 0.45239612  -MSE: 135.99798902775834  -Train Accuracy:  0.8060606\n",
      "epoch:  107  -  cost: 0.45601195  -MSE: 133.13564272870875  -Train Accuracy:  0.76363635\n",
      "epoch:  108  -  cost: 0.45020548  -MSE: 135.9450498262052  -Train Accuracy:  0.8121212\n",
      "epoch:  109  -  cost: 0.45431194  -MSE: 133.0704369625435  -Train Accuracy:  0.76969695\n",
      "epoch:  110  -  cost: 0.4491802  -MSE: 135.99293503767498  -Train Accuracy:  0.8121212\n",
      "epoch:  111  -  cost: 0.45334405  -MSE: 133.0642089821103  -Train Accuracy:  0.77575755\n",
      "epoch:  112  -  cost: 0.44831955  -MSE: 136.07673642291616  -Train Accuracy:  0.8121212\n",
      "epoch:  113  -  cost: 0.4525605  -MSE: 133.082717803839  -Train Accuracy:  0.7818182\n",
      "epoch:  114  -  cost: 0.4485937  -MSE: 136.33612154775807  -Train Accuracy:  0.8060606\n",
      "epoch:  115  -  cost: 0.4544153  -MSE: 133.06098844879455  -Train Accuracy:  0.7818182\n",
      "epoch:  116  -  cost: 0.44998112  -MSE: 136.36715110367717  -Train Accuracy:  0.7939394\n",
      "epoch:  117  -  cost: 0.45560035  -MSE: 132.9600319074645  -Train Accuracy:  0.7818182\n",
      "epoch:  118  -  cost: 0.4494388  -MSE: 136.44784686848024  -Train Accuracy:  0.8\n",
      "epoch:  119  -  cost: 0.4583279  -MSE: 132.63280163333457  -Train Accuracy:  0.77575755\n",
      "epoch:  120  -  cost: 0.45345342  -MSE: 136.37217499829785  -Train Accuracy:  0.8060606\n",
      "epoch:  121  -  cost: 0.45978564  -MSE: 132.72074904274064  -Train Accuracy:  0.77575755\n",
      "epoch:  122  -  cost: 0.45163652  -MSE: 136.34405217769813  -Train Accuracy:  0.8\n",
      "epoch:  123  -  cost: 0.46158785  -MSE: 132.14498776094902  -Train Accuracy:  0.77575755\n",
      "epoch:  124  -  cost: 0.45496282  -MSE: 136.10731935772807  -Train Accuracy:  0.8\n",
      "epoch:  125  -  cost: 0.4620549  -MSE: 132.11825225146484  -Train Accuracy:  0.77575755\n",
      "epoch:  126  -  cost: 0.45260894  -MSE: 135.93130777849433  -Train Accuracy:  0.8\n",
      "epoch:  127  -  cost: 0.46157828  -MSE: 131.74875682449033  -Train Accuracy:  0.77575755\n",
      "epoch:  128  -  cost: 0.45286492  -MSE: 135.7333261473466  -Train Accuracy:  0.8\n",
      "epoch:  129  -  cost: 0.45936903  -MSE: 131.67553901431035  -Train Accuracy:  0.77575755\n",
      "epoch:  130  -  cost: 0.44901946  -MSE: 135.41481288540203  -Train Accuracy:  0.8\n",
      "epoch:  131  -  cost: 0.4563165  -MSE: 131.34723359600568  -Train Accuracy:  0.77575755\n",
      "epoch:  132  -  cost: 0.44720298  -MSE: 135.24018083407307  -Train Accuracy:  0.8\n",
      "epoch:  133  -  cost: 0.45403942  -MSE: 131.2212643692117  -Train Accuracy:  0.77575755\n",
      "epoch:  134  -  cost: 0.44414875  -MSE: 135.00509845675202  -Train Accuracy:  0.8060606\n",
      "epoch:  135  -  cost: 0.44976893  -MSE: 131.12608490738597  -Train Accuracy:  0.7818182\n",
      "epoch:  136  -  cost: 0.44179225  -MSE: 134.93620663008036  -Train Accuracy:  0.8060606\n",
      "epoch:  137  -  cost: 0.4476766  -MSE: 131.15585835440157  -Train Accuracy:  0.7818182\n",
      "epoch:  138  -  cost: 0.44031325  -MSE: 134.8979721827631  -Train Accuracy:  0.8060606\n",
      "epoch:  139  -  cost: 0.44684368  -MSE: 130.89239365076688  -Train Accuracy:  0.7878788\n",
      "epoch:  140  -  cost: 0.4395838  -MSE: 134.59190038404694  -Train Accuracy:  0.8121212\n",
      "epoch:  141  -  cost: 0.44540235  -MSE: 130.8691876504506  -Train Accuracy:  0.7878788\n",
      "epoch:  142  -  cost: 0.43800658  -MSE: 134.6060991254507  -Train Accuracy:  0.8181818\n",
      "epoch:  143  -  cost: 0.44666845  -MSE: 130.45638885837374  -Train Accuracy:  0.7878788\n",
      "epoch:  144  -  cost: 0.4380332  -MSE: 134.23641578100387  -Train Accuracy:  0.8181818\n",
      "epoch:  145  -  cost: 0.44209448  -MSE: 130.70178579004292  -Train Accuracy:  0.7878788\n",
      "epoch:  146  -  cost: 0.4344887  -MSE: 134.32855671669404  -Train Accuracy:  0.8181818\n",
      "epoch:  147  -  cost: 0.44049382  -MSE: 130.23363540312906  -Train Accuracy:  0.7878788\n",
      "epoch:  148  -  cost: 0.43308324  -MSE: 133.9743557705008  -Train Accuracy:  0.8181818\n",
      "epoch:  149  -  cost: 0.43783727  -MSE: 130.38393589042363  -Train Accuracy:  0.7878788\n",
      "epoch:  150  -  cost: 0.4301841  -MSE: 133.93291087356948  -Train Accuracy:  0.8181818\n",
      "epoch:  151  -  cost: 0.4329402  -MSE: 130.21896984135813  -Train Accuracy:  0.7878788\n",
      "epoch:  152  -  cost: 0.42572415  -MSE: 133.85829507396778  -Train Accuracy:  0.830303\n",
      "epoch:  153  -  cost: 0.4301321  -MSE: 130.2700776688943  -Train Accuracy:  0.7878788\n",
      "epoch:  154  -  cost: 0.4242845  -MSE: 133.73509485770515  -Train Accuracy:  0.830303\n",
      "epoch:  155  -  cost: 0.4281293  -MSE: 130.2484686912196  -Train Accuracy:  0.7939394\n",
      "epoch:  156  -  cost: 0.4219664  -MSE: 133.6364843793817  -Train Accuracy:  0.8363636\n",
      "epoch:  157  -  cost: 0.42754984  -MSE: 129.9690543915839  -Train Accuracy:  0.7878788\n",
      "epoch:  158  -  cost: 0.4208355  -MSE: 133.44836460350612  -Train Accuracy:  0.8363636\n",
      "epoch:  159  -  cost: 0.42305428  -MSE: 130.25637289859787  -Train Accuracy:  0.8\n",
      "epoch:  160  -  cost: 0.4190736  -MSE: 133.6199647413599  -Train Accuracy:  0.8363636\n",
      "epoch:  161  -  cost: 0.42556426  -MSE: 129.8708631071805  -Train Accuracy:  0.7939394\n",
      "epoch:  162  -  cost: 0.41871533  -MSE: 133.33934847549622  -Train Accuracy:  0.8363636\n",
      "epoch:  163  -  cost: 0.42005903  -MSE: 130.18253921481872  -Train Accuracy:  0.8\n",
      "epoch:  164  -  cost: 0.41493303  -MSE: 133.42408109235095  -Train Accuracy:  0.8424242\n",
      "epoch:  165  -  cost: 0.41991243  -MSE: 129.9468188074083  -Train Accuracy:  0.8\n",
      "epoch:  166  -  cost: 0.4150582  -MSE: 133.30660955795383  -Train Accuracy:  0.8363636\n",
      "epoch:  167  -  cost: 0.42154276  -MSE: 129.61942913794806  -Train Accuracy:  0.7939394\n",
      "epoch:  168  -  cost: 0.41647223  -MSE: 133.1734940239568  -Train Accuracy:  0.8363636\n",
      "epoch:  169  -  cost: 0.4195681  -MSE: 129.72505086292793  -Train Accuracy:  0.8060606\n",
      "epoch:  170  -  cost: 0.41349632  -MSE: 133.14997644472376  -Train Accuracy:  0.830303\n",
      "epoch:  171  -  cost: 0.41801202  -MSE: 129.44371630302967  -Train Accuracy:  0.8060606\n",
      "epoch:  172  -  cost: 0.41239208  -MSE: 132.93416973902026  -Train Accuracy:  0.8363636\n",
      "epoch:  173  -  cost: 0.41520908  -MSE: 129.59974235806163  -Train Accuracy:  0.8060606\n",
      "epoch:  174  -  cost: 0.4099167  -MSE: 132.96092182812262  -Train Accuracy:  0.8424242\n",
      "epoch:  175  -  cost: 0.4142612  -MSE: 129.299738726607  -Train Accuracy:  0.8121212\n",
      "epoch:  176  -  cost: 0.40888128  -MSE: 132.74370286486797  -Train Accuracy:  0.8363636\n",
      "epoch:  177  -  cost: 0.4108578  -MSE: 129.45989704869885  -Train Accuracy:  0.8121212\n",
      "epoch:  178  -  cost: 0.4051303  -MSE: 132.66121783259965  -Train Accuracy:  0.8424242\n",
      "epoch:  179  -  cost: 0.40617046  -MSE: 129.46508462384355  -Train Accuracy:  0.8121212\n",
      "epoch:  180  -  cost: 0.40218377  -MSE: 132.6139546612413  -Train Accuracy:  0.8424242\n",
      "epoch:  181  -  cost: 0.40467292  -MSE: 129.41428165317512  -Train Accuracy:  0.8121212\n",
      "epoch:  182  -  cost: 0.40117267  -MSE: 132.5650046993988  -Train Accuracy:  0.8424242\n",
      "epoch:  183  -  cost: 0.4038411  -MSE: 129.3488117183978  -Train Accuracy:  0.8121212\n",
      "epoch:  184  -  cost: 0.399622  -MSE: 132.4945186917797  -Train Accuracy:  0.8424242\n",
      "epoch:  185  -  cost: 0.4019519  -MSE: 129.34427826663966  -Train Accuracy:  0.8121212\n",
      "epoch:  186  -  cost: 0.39763054  -MSE: 132.48118023098363  -Train Accuracy:  0.8424242\n",
      "epoch:  187  -  cost: 0.3992312  -MSE: 129.45641772023683  -Train Accuracy:  0.8121212\n",
      "epoch:  188  -  cost: 0.3944158  -MSE: 132.44752929064947  -Train Accuracy:  0.8424242\n",
      "epoch:  189  -  cost: 0.39500856  -MSE: 129.5510767803895  -Train Accuracy:  0.8242424\n",
      "epoch:  190  -  cost: 0.39184856  -MSE: 132.48972169472623  -Train Accuracy:  0.8424242\n",
      "epoch:  191  -  cost: 0.39391878  -MSE: 129.71580688750345  -Train Accuracy:  0.8242424\n",
      "epoch:  192  -  cost: 0.39121458  -MSE: 132.63476351884725  -Train Accuracy:  0.8424242\n",
      "epoch:  193  -  cost: 0.39437935  -MSE: 129.52457656004935  -Train Accuracy:  0.8181818\n",
      "epoch:  194  -  cost: 0.39036298  -MSE: 132.46853274858236  -Train Accuracy:  0.8424242\n",
      "epoch:  195  -  cost: 0.39015248  -MSE: 129.80439944189865  -Train Accuracy:  0.8242424\n",
      "epoch:  196  -  cost: 0.3871931  -MSE: 132.5865279216561  -Train Accuracy:  0.8424242\n",
      "epoch:  197  -  cost: 0.38950709  -MSE: 129.7883898652582  -Train Accuracy:  0.8242424\n",
      "epoch:  198  -  cost: 0.38657576  -MSE: 132.62932004515534  -Train Accuracy:  0.8424242\n",
      "epoch:  199  -  cost: 0.38857883  -MSE: 129.79920230657254  -Train Accuracy:  0.8242424\n",
      "epoch:  200  -  cost: 0.38530788  -MSE: 132.62992896712183  -Train Accuracy:  0.8424242\n",
      "epoch:  201  -  cost: 0.38709697  -MSE: 129.90611188031917  -Train Accuracy:  0.8242424\n",
      "epoch:  202  -  cost: 0.38415942  -MSE: 132.676684114711  -Train Accuracy:  0.8424242\n",
      "epoch:  203  -  cost: 0.386205  -MSE: 129.99048653997053  -Train Accuracy:  0.8242424\n",
      "epoch:  204  -  cost: 0.38290885  -MSE: 132.74063973858907  -Train Accuracy:  0.8424242\n",
      "epoch:  205  -  cost: 0.3863067  -MSE: 129.7685581837763  -Train Accuracy:  0.8181818\n",
      "epoch:  206  -  cost: 0.38287702  -MSE: 132.65247654241531  -Train Accuracy:  0.8424242\n",
      "epoch:  207  -  cost: 0.38518223  -MSE: 129.94779035191416  -Train Accuracy:  0.8181818\n",
      "epoch:  208  -  cost: 0.38196114  -MSE: 132.74816596757015  -Train Accuracy:  0.8424242\n",
      "epoch:  209  -  cost: 0.38354793  -MSE: 129.964212362214  -Train Accuracy:  0.8181818\n",
      "epoch:  210  -  cost: 0.37958387  -MSE: 132.78406827017585  -Train Accuracy:  0.8424242\n",
      "epoch:  211  -  cost: 0.38230973  -MSE: 129.98063785681748  -Train Accuracy:  0.8181818\n",
      "epoch:  212  -  cost: 0.3784784  -MSE: 132.65590509086655  -Train Accuracy:  0.8424242\n",
      "epoch:  213  -  cost: 0.37874526  -MSE: 130.21618105953945  -Train Accuracy:  0.8363636\n",
      "epoch:  214  -  cost: 0.37471056  -MSE: 132.7657142959778  -Train Accuracy:  0.8484849\n",
      "epoch:  215  -  cost: 0.37574345  -MSE: 130.0738059110629  -Train Accuracy:  0.8363636\n",
      "epoch:  216  -  cost: 0.37215883  -MSE: 132.57356970602788  -Train Accuracy:  0.8484849\n",
      "epoch:  217  -  cost: 0.37216347  -MSE: 130.46652477415032  -Train Accuracy:  0.8424242\n",
      "epoch:  218  -  cost: 0.36987674  -MSE: 132.8616370223564  -Train Accuracy:  0.8484849\n",
      "epoch:  219  -  cost: 0.37081265  -MSE: 130.37935225276374  -Train Accuracy:  0.8424242\n",
      "epoch:  220  -  cost: 0.36781347  -MSE: 132.69995867844491  -Train Accuracy:  0.8484849\n",
      "epoch:  221  -  cost: 0.3669774  -MSE: 130.87941896472142  -Train Accuracy:  0.8424242\n",
      "epoch:  222  -  cost: 0.365188  -MSE: 133.09952271651477  -Train Accuracy:  0.8484849\n",
      "epoch:  223  -  cost: 0.36544964  -MSE: 130.9848864664828  -Train Accuracy:  0.8363636\n",
      "epoch:  224  -  cost: 0.3637994  -MSE: 133.20151047801417  -Train Accuracy:  0.8484849\n",
      "epoch:  225  -  cost: 0.36324063  -MSE: 131.3718567530291  -Train Accuracy:  0.8363636\n",
      "epoch:  226  -  cost: 0.3618997  -MSE: 133.422493608208  -Train Accuracy:  0.8484849\n",
      "epoch:  227  -  cost: 0.36171663  -MSE: 131.4637510139753  -Train Accuracy:  0.8363636\n",
      "epoch:  228  -  cost: 0.36079448  -MSE: 133.51248366894575  -Train Accuracy:  0.8484849\n",
      "epoch:  229  -  cost: 0.36033255  -MSE: 131.70438020608975  -Train Accuracy:  0.8424242\n",
      "epoch:  230  -  cost: 0.35918576  -MSE: 133.6290558322095  -Train Accuracy:  0.8424242\n",
      "epoch:  231  -  cost: 0.35863763  -MSE: 131.91585396770546  -Train Accuracy:  0.8424242\n",
      "epoch:  232  -  cost: 0.3576871  -MSE: 133.7852246556447  -Train Accuracy:  0.8424242\n",
      "epoch:  233  -  cost: 0.35700017  -MSE: 132.14837935536914  -Train Accuracy:  0.8484849\n",
      "epoch:  234  -  cost: 0.35643774  -MSE: 133.89755821044983  -Train Accuracy:  0.8424242\n",
      "epoch:  235  -  cost: 0.35594654  -MSE: 132.33747000024067  -Train Accuracy:  0.8484849\n",
      "epoch:  236  -  cost: 0.3550889  -MSE: 134.04705784999476  -Train Accuracy:  0.8484849\n",
      "epoch:  237  -  cost: 0.35462838  -MSE: 132.49366288342748  -Train Accuracy:  0.8484849\n",
      "epoch:  238  -  cost: 0.35406098  -MSE: 134.17687813077652  -Train Accuracy:  0.8484849\n",
      "epoch:  239  -  cost: 0.35405767  -MSE: 132.62985548909577  -Train Accuracy:  0.8484849\n",
      "epoch:  240  -  cost: 0.3531027  -MSE: 134.2801471637321  -Train Accuracy:  0.8545455\n",
      "epoch:  241  -  cost: 0.35371417  -MSE: 132.640813225769  -Train Accuracy:  0.8484849\n",
      "epoch:  242  -  cost: 0.35316688  -MSE: 134.52148601944322  -Train Accuracy:  0.8545455\n",
      "epoch:  243  -  cost: 0.3537965  -MSE: 132.8168514585646  -Train Accuracy:  0.8424242\n",
      "epoch:  244  -  cost: 0.35332006  -MSE: 134.74304023606737  -Train Accuracy:  0.8545455\n",
      "epoch:  245  -  cost: 0.35363042  -MSE: 133.09233760640095  -Train Accuracy:  0.8424242\n",
      "epoch:  246  -  cost: 0.35262644  -MSE: 134.98527618264194  -Train Accuracy:  0.8545455\n",
      "epoch:  247  -  cost: 0.3530277  -MSE: 133.19617831900777  -Train Accuracy:  0.8424242\n",
      "epoch:  248  -  cost: 0.35238066  -MSE: 135.11774900441569  -Train Accuracy:  0.8545455\n",
      "epoch:  249  -  cost: 0.35322762  -MSE: 133.27158094318742  -Train Accuracy:  0.8363636\n",
      "epoch:  250  -  cost: 0.35263377  -MSE: 135.3086398482581  -Train Accuracy:  0.8484849\n",
      "epoch:  251  -  cost: 0.3531644  -MSE: 133.3721428272099  -Train Accuracy:  0.8424242\n",
      "epoch:  252  -  cost: 0.3523356  -MSE: 135.42403855968874  -Train Accuracy:  0.8484849\n",
      "epoch:  253  -  cost: 0.35356978  -MSE: 133.35652936161858  -Train Accuracy:  0.8424242\n",
      "epoch:  254  -  cost: 0.35283625  -MSE: 135.55532085922337  -Train Accuracy:  0.8484849\n",
      "epoch:  255  -  cost: 0.3542249  -MSE: 133.49503031584496  -Train Accuracy:  0.8424242\n",
      "epoch:  256  -  cost: 0.35298222  -MSE: 135.74397692972664  -Train Accuracy:  0.8484849\n",
      "epoch:  257  -  cost: 0.3544681  -MSE: 133.45288424302248  -Train Accuracy:  0.8424242\n",
      "epoch:  258  -  cost: 0.35299593  -MSE: 135.85422789636146  -Train Accuracy:  0.8484849\n",
      "epoch:  259  -  cost: 0.35409003  -MSE: 133.68072549100566  -Train Accuracy:  0.8484849\n",
      "epoch:  260  -  cost: 0.35285035  -MSE: 136.02958353063894  -Train Accuracy:  0.8484849\n",
      "epoch:  261  -  cost: 0.35449317  -MSE: 133.67255082604987  -Train Accuracy:  0.8424242\n",
      "epoch:  262  -  cost: 0.35316715  -MSE: 136.11380244958266  -Train Accuracy:  0.8484849\n",
      "epoch:  263  -  cost: 0.35454088  -MSE: 133.76484532011966  -Train Accuracy:  0.8424242\n",
      "epoch:  264  -  cost: 0.35259798  -MSE: 136.23181671678657  -Train Accuracy:  0.8484849\n",
      "epoch:  265  -  cost: 0.35478792  -MSE: 133.67007674962295  -Train Accuracy:  0.8484849\n",
      "epoch:  266  -  cost: 0.35298833  -MSE: 136.3068866748442  -Train Accuracy:  0.8545455\n",
      "epoch:  267  -  cost: 0.35468546  -MSE: 133.8395076610644  -Train Accuracy:  0.8484849\n",
      "epoch:  268  -  cost: 0.35302535  -MSE: 136.48882569883185  -Train Accuracy:  0.8545455\n",
      "epoch:  269  -  cost: 0.3548382  -MSE: 133.91502834094481  -Train Accuracy:  0.8424242\n",
      "epoch:  270  -  cost: 0.35353017  -MSE: 136.68276600901274  -Train Accuracy:  0.8545455\n",
      "epoch:  271  -  cost: 0.35781172  -MSE: 133.7049438414347  -Train Accuracy:  0.8424242\n",
      "epoch:  272  -  cost: 0.35636374  -MSE: 136.7463125556789  -Train Accuracy:  0.8545455\n",
      "epoch:  273  -  cost: 0.36023933  -MSE: 133.76678841589322  -Train Accuracy:  0.8363636\n",
      "epoch:  274  -  cost: 0.35818753  -MSE: 136.9271241628773  -Train Accuracy:  0.8484849\n",
      "epoch:  275  -  cost: 0.36375314  -MSE: 133.5004896588824  -Train Accuracy:  0.8363636\n",
      "epoch:  276  -  cost: 0.3599626  -MSE: 136.85082761718527  -Train Accuracy:  0.8545455\n",
      "epoch:  277  -  cost: 0.36479336  -MSE: 133.52720283704826  -Train Accuracy:  0.8363636\n",
      "epoch:  278  -  cost: 0.3614054  -MSE: 136.94787258193602  -Train Accuracy:  0.8545455\n",
      "epoch:  279  -  cost: 0.3677379  -MSE: 133.17782849429702  -Train Accuracy:  0.8363636\n",
      "epoch:  280  -  cost: 0.36187202  -MSE: 136.5761657585818  -Train Accuracy:  0.8545455\n",
      "epoch:  281  -  cost: 0.36410147  -MSE: 133.29429892329344  -Train Accuracy:  0.8363636\n",
      "epoch:  282  -  cost: 0.3605601  -MSE: 136.71278183707082  -Train Accuracy:  0.8545455\n",
      "epoch:  283  -  cost: 0.36555824  -MSE: 133.16168176936378  -Train Accuracy:  0.8363636\n",
      "epoch:  284  -  cost: 0.3603235  -MSE: 136.64822151795744  -Train Accuracy:  0.8545455\n",
      "epoch:  285  -  cost: 0.3619542  -MSE: 133.32057368792888  -Train Accuracy:  0.8363636\n",
      "epoch:  286  -  cost: 0.35732794  -MSE: 136.73237611493485  -Train Accuracy:  0.8545455\n",
      "epoch:  287  -  cost: 0.36208215  -MSE: 133.14281254893208  -Train Accuracy:  0.8363636\n",
      "epoch:  288  -  cost: 0.35703933  -MSE: 136.59218598671387  -Train Accuracy:  0.8545455\n",
      "epoch:  289  -  cost: 0.3586678  -MSE: 133.33009844606417  -Train Accuracy:  0.8363636\n",
      "epoch:  290  -  cost: 0.35448435  -MSE: 136.61050631694684  -Train Accuracy:  0.8545455\n",
      "epoch:  291  -  cost: 0.35776222  -MSE: 133.19630941122446  -Train Accuracy:  0.8363636\n",
      "epoch:  292  -  cost: 0.35321325  -MSE: 136.50114655309588  -Train Accuracy:  0.8606061\n",
      "epoch:  293  -  cost: 0.35665283  -MSE: 133.25105272231178  -Train Accuracy:  0.8363636\n",
      "epoch:  294  -  cost: 0.35266736  -MSE: 136.56474647334102  -Train Accuracy:  0.8545455\n",
      "epoch:  295  -  cost: 0.3552856  -MSE: 133.26077822705597  -Train Accuracy:  0.8363636\n",
      "epoch:  296  -  cost: 0.3502483  -MSE: 136.5514070287177  -Train Accuracy:  0.8606061\n",
      "epoch:  297  -  cost: 0.3534791  -MSE: 133.3656510043587  -Train Accuracy:  0.8363636\n",
      "epoch:  298  -  cost: 0.34951916  -MSE: 136.60272867125587  -Train Accuracy:  0.8606061\n",
      "epoch:  299  -  cost: 0.35098866  -MSE: 133.3516687958512  -Train Accuracy:  0.8363636\n",
      "epoch:  300  -  cost: 0.34642208  -MSE: 136.5014520797541  -Train Accuracy:  0.8606061\n",
      "epoch:  301  -  cost: 0.3489493  -MSE: 133.38985261995938  -Train Accuracy:  0.8363636\n",
      "epoch:  302  -  cost: 0.34505698  -MSE: 136.47181273296468  -Train Accuracy:  0.8606061\n",
      "epoch:  303  -  cost: 0.34590545  -MSE: 133.4487972560054  -Train Accuracy:  0.8424242\n",
      "epoch:  304  -  cost: 0.34162015  -MSE: 136.36735662645611  -Train Accuracy:  0.8606061\n",
      "epoch:  305  -  cost: 0.34121594  -MSE: 133.66946303216832  -Train Accuracy:  0.8484849\n",
      "epoch:  306  -  cost: 0.3377228  -MSE: 136.31997331676286  -Train Accuracy:  0.8666667\n",
      "epoch:  307  -  cost: 0.3378486  -MSE: 133.7965467648987  -Train Accuracy:  0.8545455\n",
      "epoch:  308  -  cost: 0.33494473  -MSE: 136.28427465319592  -Train Accuracy:  0.8666667\n",
      "epoch:  309  -  cost: 0.33567858  -MSE: 133.84638373259938  -Train Accuracy:  0.8545455\n",
      "epoch:  310  -  cost: 0.33281338  -MSE: 136.28486383311906  -Train Accuracy:  0.8787879\n",
      "epoch:  311  -  cost: 0.3337306  -MSE: 134.00058202013082  -Train Accuracy:  0.8545455\n",
      "epoch:  312  -  cost: 0.33100614  -MSE: 136.30480588164377  -Train Accuracy:  0.8727273\n",
      "epoch:  313  -  cost: 0.33138496  -MSE: 134.11222793973724  -Train Accuracy:  0.8484849\n",
      "epoch:  314  -  cost: 0.3290738  -MSE: 136.40424621198216  -Train Accuracy:  0.8727273\n",
      "epoch:  315  -  cost: 0.3296456  -MSE: 134.3318012499744  -Train Accuracy:  0.8484849\n",
      "epoch:  316  -  cost: 0.3277994  -MSE: 136.5605120392992  -Train Accuracy:  0.8666667\n",
      "epoch:  317  -  cost: 0.32903442  -MSE: 134.4091983754795  -Train Accuracy:  0.8484849\n",
      "epoch:  318  -  cost: 0.3270034  -MSE: 136.62734895561238  -Train Accuracy:  0.8727273\n",
      "epoch:  319  -  cost: 0.32809317  -MSE: 134.5182644348543  -Train Accuracy:  0.8484849\n",
      "epoch:  320  -  cost: 0.32604095  -MSE: 136.71486780250987  -Train Accuracy:  0.8787879\n",
      "epoch:  321  -  cost: 0.32619312  -MSE: 134.6770568212518  -Train Accuracy:  0.8484849\n",
      "epoch:  322  -  cost: 0.3241721  -MSE: 136.77849405502855  -Train Accuracy:  0.8666667\n",
      "epoch:  323  -  cost: 0.32500124  -MSE: 134.78281821817558  -Train Accuracy:  0.8484849\n",
      "epoch:  324  -  cost: 0.32335493  -MSE: 136.88333802777237  -Train Accuracy:  0.8727273\n",
      "epoch:  325  -  cost: 0.32385647  -MSE: 134.96840495231868  -Train Accuracy:  0.8484849\n",
      "epoch:  326  -  cost: 0.3221057  -MSE: 136.9991859798532  -Train Accuracy:  0.8666667\n",
      "epoch:  327  -  cost: 0.32355762  -MSE: 134.95486486492922  -Train Accuracy:  0.8484849\n",
      "epoch:  328  -  cost: 0.3216357  -MSE: 137.06078913932478  -Train Accuracy:  0.8787879\n",
      "epoch:  329  -  cost: 0.32217875  -MSE: 135.1433492963688  -Train Accuracy:  0.8484849\n",
      "epoch:  330  -  cost: 0.3204372  -MSE: 137.14052956570117  -Train Accuracy:  0.8787879\n",
      "epoch:  331  -  cost: 0.32152572  -MSE: 135.19700801623713  -Train Accuracy:  0.8484849\n",
      "epoch:  332  -  cost: 0.3198987  -MSE: 137.27671074293093  -Train Accuracy:  0.8787879\n",
      "epoch:  333  -  cost: 0.32037273  -MSE: 135.38369389372855  -Train Accuracy:  0.8545455\n",
      "epoch:  334  -  cost: 0.3185728  -MSE: 137.37284021490782  -Train Accuracy:  0.8787879\n",
      "epoch:  335  -  cost: 0.319484  -MSE: 135.51284349381254  -Train Accuracy:  0.8545455\n",
      "epoch:  336  -  cost: 0.3178358  -MSE: 137.48985323604097  -Train Accuracy:  0.8848485\n",
      "epoch:  337  -  cost: 0.31864864  -MSE: 135.58036566526144  -Train Accuracy:  0.8545455\n",
      "epoch:  338  -  cost: 0.31700355  -MSE: 137.58439092747798  -Train Accuracy:  0.8787879\n",
      "epoch:  339  -  cost: 0.3180652  -MSE: 135.65964597138276  -Train Accuracy:  0.8545455\n",
      "epoch:  340  -  cost: 0.31636578  -MSE: 137.67810304865574  -Train Accuracy:  0.8848485\n",
      "epoch:  341  -  cost: 0.31726152  -MSE: 135.8213581118583  -Train Accuracy:  0.8545455\n",
      "epoch:  342  -  cost: 0.3159312  -MSE: 137.86664020443374  -Train Accuracy:  0.8848485\n",
      "epoch:  343  -  cost: 0.31781456  -MSE: 135.79069491867295  -Train Accuracy:  0.8545455\n",
      "epoch:  344  -  cost: 0.31627023  -MSE: 137.9544586253554  -Train Accuracy:  0.8787879\n",
      "epoch:  345  -  cost: 0.3178861  -MSE: 135.8214075935139  -Train Accuracy:  0.8484849\n",
      "epoch:  346  -  cost: 0.3164664  -MSE: 138.13069851045591  -Train Accuracy:  0.8727273\n",
      "epoch:  347  -  cost: 0.31874657  -MSE: 135.836090885704  -Train Accuracy:  0.8545455\n",
      "epoch:  348  -  cost: 0.31698975  -MSE: 138.29072410849093  -Train Accuracy:  0.8727273\n",
      "epoch:  349  -  cost: 0.31905174  -MSE: 135.92143760586762  -Train Accuracy:  0.8545455\n",
      "epoch:  350  -  cost: 0.3171411  -MSE: 138.38281316581802  -Train Accuracy:  0.8727273\n",
      "epoch:  351  -  cost: 0.3198608  -MSE: 135.8771155459757  -Train Accuracy:  0.8545455\n",
      "epoch:  352  -  cost: 0.31769422  -MSE: 138.4803397349968  -Train Accuracy:  0.8787879\n",
      "epoch:  353  -  cost: 0.3196543  -MSE: 135.96287283737385  -Train Accuracy:  0.8545455\n",
      "epoch:  354  -  cost: 0.3180984  -MSE: 138.57808737200043  -Train Accuracy:  0.8787879\n",
      "epoch:  355  -  cost: 0.321226  -MSE: 135.79514333977676  -Train Accuracy:  0.8545455\n",
      "epoch:  356  -  cost: 0.318  -MSE: 138.4527932204291  -Train Accuracy:  0.8787879\n",
      "epoch:  357  -  cost: 0.31982636  -MSE: 135.807066999447  -Train Accuracy:  0.8545455\n",
      "epoch:  358  -  cost: 0.31744164  -MSE: 138.50080794612106  -Train Accuracy:  0.8787879\n",
      "epoch:  359  -  cost: 0.31987068  -MSE: 135.86963268750029  -Train Accuracy:  0.8545455\n",
      "epoch:  360  -  cost: 0.31718758  -MSE: 138.54980870793258  -Train Accuracy:  0.8787879\n",
      "epoch:  361  -  cost: 0.32086262  -MSE: 135.822689937728  -Train Accuracy:  0.8545455\n",
      "epoch:  362  -  cost: 0.3187835  -MSE: 138.58954177183261  -Train Accuracy:  0.8848485\n",
      "epoch:  363  -  cost: 0.32220477  -MSE: 135.7695065654243  -Train Accuracy:  0.8484849\n",
      "epoch:  364  -  cost: 0.31958115  -MSE: 138.67215396674533  -Train Accuracy:  0.8787879\n",
      "epoch:  365  -  cost: 0.3237124  -MSE: 135.63606539491377  -Train Accuracy:  0.8484849\n",
      "epoch:  366  -  cost: 0.32117864  -MSE: 138.71878124336322  -Train Accuracy:  0.8787879\n",
      "epoch:  367  -  cost: 0.32549992  -MSE: 135.52131243738054  -Train Accuracy:  0.8424242\n",
      "epoch:  368  -  cost: 0.32306832  -MSE: 138.8021021150159  -Train Accuracy:  0.8787879\n",
      "epoch:  369  -  cost: 0.32888815  -MSE: 135.3064318580361  -Train Accuracy:  0.8363636\n",
      "epoch:  370  -  cost: 0.32551563  -MSE: 138.77619497103927  -Train Accuracy:  0.8606061\n",
      "epoch:  371  -  cost: 0.33110258  -MSE: 135.1038554637193  -Train Accuracy:  0.8363636\n",
      "epoch:  372  -  cost: 0.32596064  -MSE: 138.52782194044872  -Train Accuracy:  0.8727273\n",
      "epoch:  373  -  cost: 0.33032775  -MSE: 134.9420836165931  -Train Accuracy:  0.8363636\n",
      "epoch:  374  -  cost: 0.3264838  -MSE: 138.52344391819094  -Train Accuracy:  0.8666667\n",
      "epoch:  375  -  cost: 0.33127886  -MSE: 134.74109881330446  -Train Accuracy:  0.8363636\n",
      "epoch:  376  -  cost: 0.32528177  -MSE: 138.26453090480385  -Train Accuracy:  0.8787879\n",
      "epoch:  377  -  cost: 0.3288717  -MSE: 134.73189499927616  -Train Accuracy:  0.8363636\n",
      "epoch:  378  -  cost: 0.3234735  -MSE: 138.11664894783758  -Train Accuracy:  0.8666667\n",
      "epoch:  379  -  cost: 0.3274012  -MSE: 134.57816257673144  -Train Accuracy:  0.8363636\n",
      "epoch:  380  -  cost: 0.32122323  -MSE: 137.91590002528923  -Train Accuracy:  0.8787879\n",
      "epoch:  381  -  cost: 0.32320106  -MSE: 134.68441340081984  -Train Accuracy:  0.8484849\n",
      "epoch:  382  -  cost: 0.31888384  -MSE: 137.97790118611542  -Train Accuracy:  0.8787879\n",
      "epoch:  383  -  cost: 0.3215813  -MSE: 134.6927506528451  -Train Accuracy:  0.8484849\n",
      "epoch:  384  -  cost: 0.31589255  -MSE: 137.74375160610776  -Train Accuracy:  0.8787879\n",
      "epoch:  385  -  cost: 0.31738752  -MSE: 134.7563447838722  -Train Accuracy:  0.8484849\n",
      "epoch:  386  -  cost: 0.31293327  -MSE: 137.7549275153839  -Train Accuracy:  0.8787879\n",
      "epoch:  387  -  cost: 0.31391042  -MSE: 134.91571682811016  -Train Accuracy:  0.8545455\n",
      "epoch:  388  -  cost: 0.30996552  -MSE: 137.75134513475643  -Train Accuracy:  0.8848485\n",
      "epoch:  389  -  cost: 0.3113969  -MSE: 135.0284078538019  -Train Accuracy:  0.8545455\n",
      "epoch:  390  -  cost: 0.30900848  -MSE: 137.844586660475  -Train Accuracy:  0.8848485\n",
      "epoch:  391  -  cost: 0.31087404  -MSE: 135.11101054161819  -Train Accuracy:  0.8545455\n",
      "epoch:  392  -  cost: 0.3079379  -MSE: 137.88212897343072  -Train Accuracy:  0.8848485\n",
      "epoch:  393  -  cost: 0.30993247  -MSE: 135.09808592023427  -Train Accuracy:  0.8545455\n",
      "epoch:  394  -  cost: 0.3071745  -MSE: 137.86550309268554  -Train Accuracy:  0.8848485\n",
      "epoch:  395  -  cost: 0.3091976  -MSE: 135.16016350862122  -Train Accuracy:  0.8545455\n",
      "epoch:  396  -  cost: 0.306442  -MSE: 137.914562062649  -Train Accuracy:  0.8848485\n",
      "epoch:  397  -  cost: 0.3080915  -MSE: 135.20510485047265  -Train Accuracy:  0.8545455\n",
      "epoch:  398  -  cost: 0.30568495  -MSE: 137.96183493237555  -Train Accuracy:  0.8848485\n",
      "epoch:  399  -  cost: 0.3083512  -MSE: 135.15937026094156  -Train Accuracy:  0.8545455\n",
      "epoch:  400  -  cost: 0.30592784  -MSE: 137.97825573524602  -Train Accuracy:  0.8848485\n",
      "epoch:  401  -  cost: 0.30792603  -MSE: 135.1883261467191  -Train Accuracy:  0.8545455\n",
      "epoch:  402  -  cost: 0.30536717  -MSE: 137.9774342519059  -Train Accuracy:  0.8848485\n",
      "epoch:  403  -  cost: 0.30694604  -MSE: 135.18416651302192  -Train Accuracy:  0.8545455\n",
      "epoch:  404  -  cost: 0.30420712  -MSE: 137.96908318037129  -Train Accuracy:  0.8848485\n",
      "epoch:  405  -  cost: 0.30560657  -MSE: 135.24790018924622  -Train Accuracy:  0.8545455\n",
      "epoch:  406  -  cost: 0.30326986  -MSE: 137.97458995541547  -Train Accuracy:  0.8848485\n",
      "epoch:  407  -  cost: 0.30540633  -MSE: 135.1475917755343  -Train Accuracy:  0.8606061\n",
      "epoch:  408  -  cost: 0.30312115  -MSE: 137.96320188271469  -Train Accuracy:  0.8848485\n",
      "epoch:  409  -  cost: 0.30523387  -MSE: 135.17078276299878  -Train Accuracy:  0.8545455\n",
      "epoch:  410  -  cost: 0.30269155  -MSE: 137.98824979854558  -Train Accuracy:  0.8848485\n",
      "epoch:  411  -  cost: 0.30394655  -MSE: 135.23508495516188  -Train Accuracy:  0.8606061\n",
      "epoch:  412  -  cost: 0.30110794  -MSE: 137.95349408035557  -Train Accuracy:  0.8848485\n",
      "epoch:  413  -  cost: 0.30315274  -MSE: 135.2856478263788  -Train Accuracy:  0.8606061\n",
      "epoch:  414  -  cost: 0.3008246  -MSE: 137.94901517925405  -Train Accuracy:  0.8848485\n",
      "epoch:  415  -  cost: 0.30307978  -MSE: 135.27655085833595  -Train Accuracy:  0.8606061\n",
      "epoch:  416  -  cost: 0.30048737  -MSE: 138.0324676803501  -Train Accuracy:  0.8909091\n",
      "epoch:  417  -  cost: 0.30325767  -MSE: 135.24818161297176  -Train Accuracy:  0.8606061\n",
      "epoch:  418  -  cost: 0.300799  -MSE: 138.07196147790296  -Train Accuracy:  0.8909091\n",
      "epoch:  419  -  cost: 0.30359918  -MSE: 135.23809566135827  -Train Accuracy:  0.8606061\n",
      "epoch:  420  -  cost: 0.30040136  -MSE: 138.0798780882975  -Train Accuracy:  0.8909091\n",
      "epoch:  421  -  cost: 0.3031722  -MSE: 135.24066308637336  -Train Accuracy:  0.8545455\n",
      "epoch:  422  -  cost: 0.3006147  -MSE: 138.11679496499914  -Train Accuracy:  0.8848485\n",
      "epoch:  423  -  cost: 0.3030122  -MSE: 135.214401967354  -Train Accuracy:  0.8545455\n",
      "epoch:  424  -  cost: 0.29995292  -MSE: 138.08643330789394  -Train Accuracy:  0.8848485\n",
      "epoch:  425  -  cost: 0.30289197  -MSE: 135.1539460617119  -Train Accuracy:  0.8545455\n",
      "epoch:  426  -  cost: 0.30034631  -MSE: 138.12322506516267  -Train Accuracy:  0.8787879\n",
      "epoch:  427  -  cost: 0.30275598  -MSE: 135.18001131914696  -Train Accuracy:  0.8545455\n",
      "epoch:  428  -  cost: 0.2997701  -MSE: 138.11247819935366  -Train Accuracy:  0.8787879\n",
      "epoch:  429  -  cost: 0.30329075  -MSE: 134.9771279116026  -Train Accuracy:  0.8484849\n",
      "epoch:  430  -  cost: 0.2998758  -MSE: 138.05205645131196  -Train Accuracy:  0.8787879\n",
      "epoch:  431  -  cost: 0.30260602  -MSE: 135.0756397659733  -Train Accuracy:  0.8484849\n",
      "epoch:  432  -  cost: 0.29910925  -MSE: 138.10914695165272  -Train Accuracy:  0.8787879\n",
      "epoch:  433  -  cost: 0.3017406  -MSE: 135.0511149725016  -Train Accuracy:  0.8545455\n",
      "epoch:  434  -  cost: 0.29850808  -MSE: 138.07051125044555  -Train Accuracy:  0.8787879\n",
      "epoch:  435  -  cost: 0.30072263  -MSE: 135.0321837616025  -Train Accuracy:  0.8545455\n",
      "epoch:  436  -  cost: 0.29807472  -MSE: 138.07718356841113  -Train Accuracy:  0.8787879\n",
      "epoch:  437  -  cost: 0.30029273  -MSE: 135.0580625059278  -Train Accuracy:  0.8545455\n",
      "epoch:  438  -  cost: 0.29657787  -MSE: 138.07639900752665  -Train Accuracy:  0.8787879\n",
      "epoch:  439  -  cost: 0.29877117  -MSE: 135.08807422224714  -Train Accuracy:  0.8545455\n",
      "epoch:  440  -  cost: 0.29596886  -MSE: 138.04370082869238  -Train Accuracy:  0.8787879\n",
      "epoch:  441  -  cost: 0.29842466  -MSE: 135.0190865795747  -Train Accuracy:  0.8545455\n",
      "epoch:  442  -  cost: 0.29462335  -MSE: 137.9579412352417  -Train Accuracy:  0.8848485\n",
      "epoch:  443  -  cost: 0.29711774  -MSE: 135.06853090617818  -Train Accuracy:  0.8545455\n",
      "epoch:  444  -  cost: 0.29390195  -MSE: 138.0064509597681  -Train Accuracy:  0.8848485\n",
      "epoch:  445  -  cost: 0.29632944  -MSE: 135.03144402616212  -Train Accuracy:  0.8545455\n",
      "epoch:  446  -  cost: 0.29272357  -MSE: 137.9226400447297  -Train Accuracy:  0.8848485\n",
      "epoch:  447  -  cost: 0.29452044  -MSE: 135.06235563759054  -Train Accuracy:  0.8606061\n",
      "epoch:  448  -  cost: 0.29115918  -MSE: 137.9135692810863  -Train Accuracy:  0.8909091\n",
      "epoch:  449  -  cost: 0.29392564  -MSE: 135.09287584190065  -Train Accuracy:  0.8666667\n",
      "epoch:  450  -  cost: 0.29070345  -MSE: 138.02207187050334  -Train Accuracy:  0.8909091\n",
      "epoch:  451  -  cost: 0.2923211  -MSE: 135.28368298347797  -Train Accuracy:  0.8666667\n",
      "epoch:  452  -  cost: 0.2902622  -MSE: 138.21548134309327  -Train Accuracy:  0.8909091\n",
      "epoch:  453  -  cost: 0.2934659  -MSE: 135.1666038765611  -Train Accuracy:  0.8545455\n",
      "epoch:  454  -  cost: 0.2913407  -MSE: 138.21501840956284  -Train Accuracy:  0.8848485\n",
      "epoch:  455  -  cost: 0.29422003  -MSE: 135.07149327480178  -Train Accuracy:  0.8545455\n",
      "epoch:  456  -  cost: 0.2909268  -MSE: 138.15834132057336  -Train Accuracy:  0.8848485\n",
      "epoch:  457  -  cost: 0.29225913  -MSE: 135.31845248963134  -Train Accuracy:  0.8606061\n",
      "epoch:  458  -  cost: 0.29000264  -MSE: 138.36124255277957  -Train Accuracy:  0.8909091\n",
      "epoch:  459  -  cost: 0.29265702  -MSE: 135.18528783705582  -Train Accuracy:  0.8606061\n",
      "epoch:  460  -  cost: 0.28968573  -MSE: 138.2116935322867  -Train Accuracy:  0.8848485\n",
      "epoch:  461  -  cost: 0.29090557  -MSE: 135.41662366380095  -Train Accuracy:  0.8666667\n",
      "epoch:  462  -  cost: 0.2884591  -MSE: 138.4470571287464  -Train Accuracy:  0.8909091\n",
      "epoch:  463  -  cost: 0.29082873  -MSE: 135.24254174722842  -Train Accuracy:  0.8606061\n",
      "epoch:  464  -  cost: 0.28877312  -MSE: 138.35534735334807  -Train Accuracy:  0.8848485\n",
      "epoch:  465  -  cost: 0.29124683  -MSE: 135.40673704321725  -Train Accuracy:  0.8606061\n",
      "epoch:  466  -  cost: 0.28877288  -MSE: 138.53131668210872  -Train Accuracy:  0.8909091\n",
      "epoch:  467  -  cost: 0.2911232  -MSE: 135.20733754258558  -Train Accuracy:  0.8606061\n",
      "epoch:  468  -  cost: 0.28895137  -MSE: 138.40818869968865  -Train Accuracy:  0.8848485\n",
      "epoch:  469  -  cost: 0.29131922  -MSE: 135.14453735167655  -Train Accuracy:  0.8606061\n",
      "epoch:  470  -  cost: 0.28807494  -MSE: 138.38821112115278  -Train Accuracy:  0.8848485\n",
      "epoch:  471  -  cost: 0.29055908  -MSE: 135.08805018971967  -Train Accuracy:  0.8606061\n",
      "epoch:  472  -  cost: 0.28759223  -MSE: 138.30497992810908  -Train Accuracy:  0.8848485\n",
      "epoch:  473  -  cost: 0.28926057  -MSE: 135.1484299180562  -Train Accuracy:  0.8606061\n",
      "epoch:  474  -  cost: 0.28607875  -MSE: 138.3205811279049  -Train Accuracy:  0.8848485\n",
      "epoch:  475  -  cost: 0.2885991  -MSE: 135.03462872968313  -Train Accuracy:  0.8606061\n",
      "epoch:  476  -  cost: 0.28618708  -MSE: 138.25083510817265  -Train Accuracy:  0.8848485\n",
      "epoch:  477  -  cost: 0.28788742  -MSE: 135.15199244145282  -Train Accuracy:  0.8606061\n",
      "epoch:  478  -  cost: 0.28481835  -MSE: 138.28439521976162  -Train Accuracy:  0.8909091\n",
      "epoch:  479  -  cost: 0.28713378  -MSE: 134.99798500804576  -Train Accuracy:  0.8606061\n",
      "epoch:  480  -  cost: 0.28494078  -MSE: 138.23071417888562  -Train Accuracy:  0.8848485\n",
      "epoch:  481  -  cost: 0.28733513  -MSE: 134.93753690584285  -Train Accuracy:  0.8606061\n",
      "epoch:  482  -  cost: 0.28378356  -MSE: 138.1257997701471  -Train Accuracy:  0.8848485\n",
      "epoch:  483  -  cost: 0.28564516  -MSE: 134.89395378236  -Train Accuracy:  0.8606061\n",
      "epoch:  484  -  cost: 0.2825171  -MSE: 138.02031922774773  -Train Accuracy:  0.8909091\n",
      "epoch:  485  -  cost: 0.28391477  -MSE: 135.08855373926775  -Train Accuracy:  0.8666667\n",
      "epoch:  486  -  cost: 0.28087568  -MSE: 138.12866061499  -Train Accuracy:  0.8909091\n",
      "epoch:  487  -  cost: 0.28239653  -MSE: 134.99932913321476  -Train Accuracy:  0.8666667\n",
      "epoch:  488  -  cost: 0.2814051  -MSE: 138.32686466202273  -Train Accuracy:  0.8909091\n",
      "epoch:  489  -  cost: 0.28327575  -MSE: 135.085618009545  -Train Accuracy:  0.8666667\n",
      "epoch:  490  -  cost: 0.2823063  -MSE: 138.53511438388682  -Train Accuracy:  0.8848485\n",
      "epoch:  491  -  cost: 0.28539875  -MSE: 135.04357753330248  -Train Accuracy:  0.8606061\n",
      "epoch:  492  -  cost: 0.28474018  -MSE: 138.66479899459105  -Train Accuracy:  0.8909091\n",
      "epoch:  493  -  cost: 0.28725016  -MSE: 135.0093052677579  -Train Accuracy:  0.8606061\n",
      "epoch:  494  -  cost: 0.28440142  -MSE: 138.5735956947076  -Train Accuracy:  0.8969697\n",
      "epoch:  495  -  cost: 0.28636378  -MSE: 135.0030076213702  -Train Accuracy:  0.8606061\n",
      "epoch:  496  -  cost: 0.28371522  -MSE: 138.59367829253966  -Train Accuracy:  0.8969697\n",
      "epoch:  497  -  cost: 0.28563762  -MSE: 134.89782703274028  -Train Accuracy:  0.8606061\n",
      "epoch:  498  -  cost: 0.28429565  -MSE: 138.60838802334044  -Train Accuracy:  0.8969697\n",
      "epoch:  499  -  cost: 0.28605112  -MSE: 134.88356831030327  -Train Accuracy:  0.8606061\n",
      "epoch:  500  -  cost: 0.28446275  -MSE: 138.60530767708298  -Train Accuracy:  0.8969697\n",
      "epoch:  501  -  cost: 0.28657797  -MSE: 134.74199279568361  -Train Accuracy:  0.8606061\n",
      "epoch:  502  -  cost: 0.28374422  -MSE: 138.47736053056576  -Train Accuracy:  0.8909091\n",
      "epoch:  503  -  cost: 0.28505364  -MSE: 134.80117045966415  -Train Accuracy:  0.8606061\n",
      "epoch:  504  -  cost: 0.28188905  -MSE: 138.3171035996325  -Train Accuracy:  0.8969697\n",
      "epoch:  505  -  cost: 0.28288385  -MSE: 134.6881266432048  -Train Accuracy:  0.8666667\n",
      "epoch:  506  -  cost: 0.28067675  -MSE: 138.3200023067731  -Train Accuracy:  0.8969697\n",
      "epoch:  507  -  cost: 0.28199318  -MSE: 134.68656260423904  -Train Accuracy:  0.8606061\n",
      "epoch:  508  -  cost: 0.28052083  -MSE: 138.37418186959516  -Train Accuracy:  0.8969697\n",
      "epoch:  509  -  cost: 0.28159901  -MSE: 134.79522655007972  -Train Accuracy:  0.8666667\n",
      "epoch:  510  -  cost: 0.27987385  -MSE: 138.415703057476  -Train Accuracy:  0.8969697\n",
      "epoch:  511  -  cost: 0.28157833  -MSE: 134.78487421697355  -Train Accuracy:  0.8666667\n",
      "epoch:  512  -  cost: 0.2802384  -MSE: 138.4726964602672  -Train Accuracy:  0.8969697\n",
      "epoch:  513  -  cost: 0.2826428  -MSE: 134.665038314083  -Train Accuracy:  0.8606061\n",
      "epoch:  514  -  cost: 0.28121823  -MSE: 138.56516871864437  -Train Accuracy:  0.8909091\n",
      "epoch:  515  -  cost: 0.28454977  -MSE: 134.65739898980956  -Train Accuracy:  0.8545455\n",
      "epoch:  516  -  cost: 0.28245303  -MSE: 138.6067141181617  -Train Accuracy:  0.8909091\n",
      "epoch:  517  -  cost: 0.28425366  -MSE: 134.60035882786073  -Train Accuracy:  0.8545455\n",
      "epoch:  518  -  cost: 0.2824158  -MSE: 138.55998105699274  -Train Accuracy:  0.8909091\n",
      "epoch:  519  -  cost: 0.28427157  -MSE: 134.57100274589942  -Train Accuracy:  0.8545455\n",
      "epoch:  520  -  cost: 0.2834265  -MSE: 138.656764349526  -Train Accuracy:  0.8848485\n",
      "epoch:  521  -  cost: 0.28542694  -MSE: 134.49099544263476  -Train Accuracy:  0.8424242\n",
      "epoch:  522  -  cost: 0.28331918  -MSE: 138.5491034812748  -Train Accuracy:  0.8848485\n",
      "epoch:  523  -  cost: 0.28609237  -MSE: 134.33344214615428  -Train Accuracy:  0.8424242\n",
      "epoch:  524  -  cost: 0.2842435  -MSE: 138.596057317945  -Train Accuracy:  0.8848485\n",
      "epoch:  525  -  cost: 0.28674105  -MSE: 134.26049721730487  -Train Accuracy:  0.8484849\n",
      "epoch:  526  -  cost: 0.28490576  -MSE: 138.47631858487864  -Train Accuracy:  0.8848485\n",
      "epoch:  527  -  cost: 0.28665668  -MSE: 134.15351572207206  -Train Accuracy:  0.8484849\n",
      "epoch:  528  -  cost: 0.28424367  -MSE: 138.4947386151009  -Train Accuracy:  0.8848485\n",
      "epoch:  529  -  cost: 0.28677857  -MSE: 134.07245429554064  -Train Accuracy:  0.8484849\n",
      "epoch:  530  -  cost: 0.28461742  -MSE: 138.3011060332912  -Train Accuracy:  0.8848485\n",
      "epoch:  531  -  cost: 0.28562003  -MSE: 133.95104417451503  -Train Accuracy:  0.8484849\n",
      "epoch:  532  -  cost: 0.28306955  -MSE: 138.25616437612177  -Train Accuracy:  0.8848485\n",
      "epoch:  533  -  cost: 0.2849123  -MSE: 133.83832544528724  -Train Accuracy:  0.8545455\n",
      "epoch:  534  -  cost: 0.28296614  -MSE: 138.11227526385224  -Train Accuracy:  0.8848485\n",
      "epoch:  535  -  cost: 0.28546464  -MSE: 133.662940030102  -Train Accuracy:  0.8484849\n",
      "epoch:  536  -  cost: 0.2823773  -MSE: 138.05024371622844  -Train Accuracy:  0.8848485\n",
      "epoch:  537  -  cost: 0.28382814  -MSE: 133.6994417140833  -Train Accuracy:  0.8545455\n",
      "epoch:  538  -  cost: 0.2820823  -MSE: 137.98439554135027  -Train Accuracy:  0.8848485\n",
      "epoch:  539  -  cost: 0.28544608  -MSE: 133.49061822585156  -Train Accuracy:  0.8484849\n",
      "epoch:  540  -  cost: 0.28179225  -MSE: 137.93560492929015  -Train Accuracy:  0.8848485\n",
      "epoch:  541  -  cost: 0.2824972  -MSE: 133.56723763233697  -Train Accuracy:  0.8545455\n",
      "epoch:  542  -  cost: 0.28067762  -MSE: 137.81185824131157  -Train Accuracy:  0.8909091\n",
      "epoch:  543  -  cost: 0.28249425  -MSE: 133.55221359660695  -Train Accuracy:  0.8545455\n",
      "epoch:  544  -  cost: 0.27928978  -MSE: 137.79200029382187  -Train Accuracy:  0.8909091\n",
      "epoch:  545  -  cost: 0.27983245  -MSE: 133.45748657293834  -Train Accuracy:  0.8606061\n",
      "epoch:  546  -  cost: 0.27776107  -MSE: 137.62055032353592  -Train Accuracy:  0.8909091\n",
      "epoch:  547  -  cost: 0.27843904  -MSE: 133.3596483067609  -Train Accuracy:  0.8666667\n",
      "epoch:  548  -  cost: 0.27585527  -MSE: 137.53022379654553  -Train Accuracy:  0.8909091\n",
      "epoch:  549  -  cost: 0.27637115  -MSE: 133.37711031742123  -Train Accuracy:  0.8666667\n",
      "epoch:  550  -  cost: 0.2745112  -MSE: 137.44061893625636  -Train Accuracy:  0.8909091\n",
      "epoch:  551  -  cost: 0.27370912  -MSE: 133.52209933936345  -Train Accuracy:  0.8666667\n",
      "epoch:  552  -  cost: 0.27124768  -MSE: 137.3580976366906  -Train Accuracy:  0.8969697\n",
      "epoch:  553  -  cost: 0.26956448  -MSE: 133.68529434455823  -Train Accuracy:  0.8666667\n",
      "epoch:  554  -  cost: 0.26819676  -MSE: 137.31283587998405  -Train Accuracy:  0.8969697\n",
      "epoch:  555  -  cost: 0.26770705  -MSE: 133.51514860631985  -Train Accuracy:  0.8727273\n",
      "epoch:  556  -  cost: 0.26605228  -MSE: 137.16176265639265  -Train Accuracy:  0.8969697\n",
      "epoch:  557  -  cost: 0.26541036  -MSE: 133.74687300818331  -Train Accuracy:  0.8787879\n",
      "epoch:  558  -  cost: 0.26369947  -MSE: 137.2236252008886  -Train Accuracy:  0.8969697\n",
      "epoch:  559  -  cost: 0.2626078  -MSE: 133.8729340064367  -Train Accuracy:  0.8848485\n",
      "epoch:  560  -  cost: 0.26185188  -MSE: 137.1852999625403  -Train Accuracy:  0.9030303\n",
      "epoch:  561  -  cost: 0.26103833  -MSE: 133.92916740469272  -Train Accuracy:  0.8848485\n",
      "epoch:  562  -  cost: 0.26077244  -MSE: 137.2606707219745  -Train Accuracy:  0.9030303\n",
      "epoch:  563  -  cost: 0.26123738  -MSE: 133.82964245157277  -Train Accuracy:  0.8848485\n",
      "epoch:  564  -  cost: 0.26011008  -MSE: 137.18344174857086  -Train Accuracy:  0.9030303\n",
      "epoch:  565  -  cost: 0.25958744  -MSE: 134.02242024239652  -Train Accuracy:  0.8909091\n",
      "epoch:  566  -  cost: 0.25948566  -MSE: 137.21705960293747  -Train Accuracy:  0.9030303\n",
      "epoch:  567  -  cost: 0.2588786  -MSE: 134.1080046468308  -Train Accuracy:  0.8909091\n",
      "epoch:  568  -  cost: 0.25822037  -MSE: 137.32633714419495  -Train Accuracy:  0.9030303\n",
      "epoch:  569  -  cost: 0.25827244  -MSE: 134.10601318781195  -Train Accuracy:  0.8909091\n",
      "epoch:  570  -  cost: 0.2577848  -MSE: 137.39944300025735  -Train Accuracy:  0.9030303\n",
      "epoch:  571  -  cost: 0.25831908  -MSE: 134.09654464555928  -Train Accuracy:  0.8909091\n",
      "epoch:  572  -  cost: 0.25813597  -MSE: 137.34486546848674  -Train Accuracy:  0.9030303\n",
      "epoch:  573  -  cost: 0.25786036  -MSE: 134.21346416709807  -Train Accuracy:  0.8909091\n",
      "epoch:  574  -  cost: 0.25717044  -MSE: 137.49912094538064  -Train Accuracy:  0.9030303\n",
      "epoch:  575  -  cost: 0.25791958  -MSE: 134.16368432428058  -Train Accuracy:  0.8909091\n",
      "epoch:  576  -  cost: 0.25796735  -MSE: 137.4955024399498  -Train Accuracy:  0.9030303\n",
      "epoch:  577  -  cost: 0.25842044  -MSE: 134.20303562001712  -Train Accuracy:  0.8909091\n",
      "epoch:  578  -  cost: 0.2572969  -MSE: 137.5615855843998  -Train Accuracy:  0.9030303\n",
      "epoch:  579  -  cost: 0.25743386  -MSE: 134.24117000012507  -Train Accuracy:  0.8909091\n",
      "epoch:  580  -  cost: 0.25737855  -MSE: 137.6530624878877  -Train Accuracy:  0.9030303\n",
      "epoch:  581  -  cost: 0.25777748  -MSE: 134.23063987830056  -Train Accuracy:  0.8909091\n",
      "epoch:  582  -  cost: 0.2568202  -MSE: 137.67372725953243  -Train Accuracy:  0.9030303\n",
      "epoch:  583  -  cost: 0.2574086  -MSE: 134.31373247734732  -Train Accuracy:  0.8848485\n",
      "epoch:  584  -  cost: 0.25716677  -MSE: 137.76961464667335  -Train Accuracy:  0.9030303\n",
      "epoch:  585  -  cost: 0.25734752  -MSE: 134.28401503237623  -Train Accuracy:  0.8787879\n",
      "epoch:  586  -  cost: 0.25630376  -MSE: 137.71413135480228  -Train Accuracy:  0.9030303\n",
      "epoch:  587  -  cost: 0.25687423  -MSE: 134.2967606373631  -Train Accuracy:  0.8848485\n",
      "epoch:  588  -  cost: 0.2559485  -MSE: 137.7279609802821  -Train Accuracy:  0.9030303\n",
      "epoch:  589  -  cost: 0.2555103  -MSE: 134.3865958013525  -Train Accuracy:  0.8909091\n",
      "epoch:  590  -  cost: 0.2544206  -MSE: 137.80668995151544  -Train Accuracy:  0.9030303\n",
      "epoch:  591  -  cost: 0.25523192  -MSE: 134.3989276697233  -Train Accuracy:  0.8909091\n",
      "epoch:  592  -  cost: 0.25455448  -MSE: 137.80279691200695  -Train Accuracy:  0.9030303\n",
      "epoch:  593  -  cost: 0.25440603  -MSE: 134.41435286766165  -Train Accuracy:  0.8909091\n",
      "epoch:  594  -  cost: 0.2536629  -MSE: 137.82662964426592  -Train Accuracy:  0.9030303\n",
      "epoch:  595  -  cost: 0.25439045  -MSE: 134.42110001312827  -Train Accuracy:  0.8909091\n",
      "epoch:  596  -  cost: 0.25342777  -MSE: 137.81437496935118  -Train Accuracy:  0.9030303\n",
      "epoch:  597  -  cost: 0.25321883  -MSE: 134.50580452466195  -Train Accuracy:  0.8909091\n",
      "epoch:  598  -  cost: 0.25253487  -MSE: 137.82010175338553  -Train Accuracy:  0.9030303\n",
      "epoch:  599  -  cost: 0.2523791  -MSE: 134.5583759929688  -Train Accuracy:  0.8909091\n",
      "epoch:  600  -  cost: 0.25101322  -MSE: 137.88444743756887  -Train Accuracy:  0.90909094\n",
      "epoch:  601  -  cost: 0.2517446  -MSE: 134.58627417014046  -Train Accuracy:  0.8909091\n",
      "epoch:  602  -  cost: 0.25150043  -MSE: 137.88633133335412  -Train Accuracy:  0.9030303\n",
      "epoch:  603  -  cost: 0.25138453  -MSE: 134.54324110355608  -Train Accuracy:  0.8909091\n",
      "epoch:  604  -  cost: 0.2513625  -MSE: 137.95290928974975  -Train Accuracy:  0.9030303\n",
      "epoch:  605  -  cost: 0.25207317  -MSE: 134.60387709562224  -Train Accuracy:  0.8848485\n",
      "epoch:  606  -  cost: 0.25134942  -MSE: 137.96345646291698  -Train Accuracy:  0.9030303\n",
      "epoch:  607  -  cost: 0.25098833  -MSE: 134.57999120285598  -Train Accuracy:  0.8909091\n",
      "epoch:  608  -  cost: 0.25002107  -MSE: 137.98401090502745  -Train Accuracy:  0.9030303\n",
      "epoch:  609  -  cost: 0.25047314  -MSE: 134.7134911407321  -Train Accuracy:  0.8909091\n",
      "epoch:  610  -  cost: 0.24985373  -MSE: 138.0403794978308  -Train Accuracy:  0.90909094\n",
      "epoch:  611  -  cost: 0.24947046  -MSE: 134.70430168299148  -Train Accuracy:  0.8909091\n",
      "epoch:  612  -  cost: 0.24850544  -MSE: 138.00638998708254  -Train Accuracy:  0.9030303\n",
      "epoch:  613  -  cost: 0.24909134  -MSE: 134.66200968978532  -Train Accuracy:  0.8909091\n",
      "epoch:  614  -  cost: 0.24910359  -MSE: 138.05459487520827  -Train Accuracy:  0.90909094\n",
      "epoch:  615  -  cost: 0.24861605  -MSE: 134.80866528855785  -Train Accuracy:  0.8909091\n",
      "epoch:  616  -  cost: 0.24788709  -MSE: 138.22360570667465  -Train Accuracy:  0.90909094\n",
      "epoch:  617  -  cost: 0.24786767  -MSE: 134.90326873416365  -Train Accuracy:  0.8909091\n",
      "epoch:  618  -  cost: 0.24854502  -MSE: 138.2835766585546  -Train Accuracy:  0.9030303\n",
      "epoch:  619  -  cost: 0.2484849  -MSE: 134.94187169625795  -Train Accuracy:  0.8848485\n",
      "epoch:  620  -  cost: 0.24813892  -MSE: 138.403011222004  -Train Accuracy:  0.9030303\n",
      "epoch:  621  -  cost: 0.24806546  -MSE: 134.9147970187544  -Train Accuracy:  0.8848485\n",
      "epoch:  622  -  cost: 0.24854699  -MSE: 138.37112270604717  -Train Accuracy:  0.9030303\n",
      "epoch:  623  -  cost: 0.24854258  -MSE: 135.0103175569928  -Train Accuracy:  0.8848485\n",
      "epoch:  624  -  cost: 0.24733168  -MSE: 138.48771783679783  -Train Accuracy:  0.90909094\n",
      "epoch:  625  -  cost: 0.24701469  -MSE: 135.01672200046445  -Train Accuracy:  0.8787879\n",
      "epoch:  626  -  cost: 0.24744006  -MSE: 138.5080880726529  -Train Accuracy:  0.9030303\n",
      "epoch:  627  -  cost: 0.24708353  -MSE: 135.00829972294247  -Train Accuracy:  0.8848485\n",
      "epoch:  628  -  cost: 0.24714582  -MSE: 138.53172992301452  -Train Accuracy:  0.9030303\n",
      "epoch:  629  -  cost: 0.24732842  -MSE: 135.10328947566865  -Train Accuracy:  0.8909091\n",
      "epoch:  630  -  cost: 0.24634871  -MSE: 138.65430533239595  -Train Accuracy:  0.90909094\n",
      "epoch:  631  -  cost: 0.24580261  -MSE: 135.11982333377577  -Train Accuracy:  0.8848485\n",
      "epoch:  632  -  cost: 0.24585523  -MSE: 138.62259547887766  -Train Accuracy:  0.9030303\n",
      "epoch:  633  -  cost: 0.2460978  -MSE: 135.22137990816563  -Train Accuracy:  0.8848485\n",
      "epoch:  634  -  cost: 0.24575637  -MSE: 138.8121754539242  -Train Accuracy:  0.90909094\n",
      "epoch:  635  -  cost: 0.24526747  -MSE: 135.25443942239156  -Train Accuracy:  0.8848485\n",
      "epoch:  636  -  cost: 0.2449574  -MSE: 138.8044031140253  -Train Accuracy:  0.90909094\n",
      "epoch:  637  -  cost: 0.24416716  -MSE: 135.38261021941128  -Train Accuracy:  0.8909091\n",
      "epoch:  638  -  cost: 0.24338628  -MSE: 138.8441348954986  -Train Accuracy:  0.90909094\n",
      "epoch:  639  -  cost: 0.24385522  -MSE: 135.42259781344723  -Train Accuracy:  0.8909091\n",
      "epoch:  640  -  cost: 0.24356015  -MSE: 138.95196619630966  -Train Accuracy:  0.90909094\n",
      "epoch:  641  -  cost: 0.24268383  -MSE: 135.56016592536565  -Train Accuracy:  0.8909091\n",
      "epoch:  642  -  cost: 0.24238914  -MSE: 139.06535971522612  -Train Accuracy:  0.90909094\n",
      "epoch:  643  -  cost: 0.24257956  -MSE: 135.62218400506305  -Train Accuracy:  0.8848485\n",
      "epoch:  644  -  cost: 0.24292298  -MSE: 139.15514913564127  -Train Accuracy:  0.91515154\n",
      "epoch:  645  -  cost: 0.24294913  -MSE: 135.62834537512475  -Train Accuracy:  0.8909091\n",
      "epoch:  646  -  cost: 0.24163747  -MSE: 139.235691030295  -Train Accuracy:  0.90909094\n",
      "epoch:  647  -  cost: 0.24193469  -MSE: 135.80109995257376  -Train Accuracy:  0.8848485\n",
      "epoch:  648  -  cost: 0.2422077  -MSE: 139.29298890413364  -Train Accuracy:  0.91515154\n",
      "epoch:  649  -  cost: 0.2428736  -MSE: 135.7664204570196  -Train Accuracy:  0.8848485\n",
      "epoch:  650  -  cost: 0.24269478  -MSE: 139.440610552426  -Train Accuracy:  0.91515154\n",
      "epoch:  651  -  cost: 0.24294038  -MSE: 135.7694985887867  -Train Accuracy:  0.8848485\n",
      "epoch:  652  -  cost: 0.24276324  -MSE: 139.44461495113734  -Train Accuracy:  0.92121214\n",
      "epoch:  653  -  cost: 0.24389887  -MSE: 135.79709922586298  -Train Accuracy:  0.8848485\n",
      "epoch:  654  -  cost: 0.24305189  -MSE: 139.58897428162865  -Train Accuracy:  0.92121214\n",
      "epoch:  655  -  cost: 0.2427092  -MSE: 135.85979843967166  -Train Accuracy:  0.8848485\n",
      "epoch:  656  -  cost: 0.24159543  -MSE: 139.54608512892304  -Train Accuracy:  0.92121214\n",
      "epoch:  657  -  cost: 0.24270782  -MSE: 135.8338755871792  -Train Accuracy:  0.8848485\n",
      "epoch:  658  -  cost: 0.24271543  -MSE: 139.6848365824863  -Train Accuracy:  0.92121214\n",
      "epoch:  659  -  cost: 0.24351513  -MSE: 135.8340401793772  -Train Accuracy:  0.8848485\n",
      "epoch:  660  -  cost: 0.24275585  -MSE: 139.75304935692333  -Train Accuracy:  0.91515154\n",
      "epoch:  661  -  cost: 0.2450368  -MSE: 135.82001987905684  -Train Accuracy:  0.8848485\n",
      "epoch:  662  -  cost: 0.24469212  -MSE: 139.8892512831682  -Train Accuracy:  0.91515154\n",
      "epoch:  663  -  cost: 0.24527091  -MSE: 135.83756984103243  -Train Accuracy:  0.8848485\n",
      "epoch:  664  -  cost: 0.24427943  -MSE: 139.8236140808323  -Train Accuracy:  0.91515154\n",
      "epoch:  665  -  cost: 0.24527341  -MSE: 135.71574568269247  -Train Accuracy:  0.8848485\n",
      "epoch:  666  -  cost: 0.24425112  -MSE: 139.72827684583913  -Train Accuracy:  0.91515154\n",
      "epoch:  667  -  cost: 0.24573223  -MSE: 135.73462044168247  -Train Accuracy:  0.8848485\n",
      "epoch:  668  -  cost: 0.24406202  -MSE: 139.86268289433264  -Train Accuracy:  0.91515154\n",
      "epoch:  669  -  cost: 0.24454087  -MSE: 135.66606500221454  -Train Accuracy:  0.8848485\n",
      "epoch:  670  -  cost: 0.24374457  -MSE: 139.6643684346111  -Train Accuracy:  0.91515154\n",
      "epoch:  671  -  cost: 0.24446759  -MSE: 135.5454828571243  -Train Accuracy:  0.8848485\n",
      "epoch:  672  -  cost: 0.24259119  -MSE: 139.6122137253632  -Train Accuracy:  0.91515154\n",
      "epoch:  673  -  cost: 0.2440875  -MSE: 135.62611782918776  -Train Accuracy:  0.8848485\n",
      "epoch:  674  -  cost: 0.24289426  -MSE: 139.7572263779013  -Train Accuracy:  0.91515154\n",
      "epoch:  675  -  cost: 0.24317278  -MSE: 135.54332991721748  -Train Accuracy:  0.8848485\n",
      "epoch:  676  -  cost: 0.2413105  -MSE: 139.50676284906456  -Train Accuracy:  0.91515154\n",
      "epoch:  677  -  cost: 0.242037  -MSE: 135.50158199517054  -Train Accuracy:  0.8848485\n",
      "epoch:  678  -  cost: 0.23966694  -MSE: 139.50390712998276  -Train Accuracy:  0.91515154\n",
      "epoch:  679  -  cost: 0.23991024  -MSE: 135.5672128115941  -Train Accuracy:  0.8848485\n",
      "epoch:  680  -  cost: 0.23920006  -MSE: 139.47418859474223  -Train Accuracy:  0.91515154\n",
      "epoch:  681  -  cost: 0.24070273  -MSE: 135.5147672976264  -Train Accuracy:  0.8848485\n",
      "epoch:  682  -  cost: 0.2385499  -MSE: 139.55493608159645  -Train Accuracy:  0.92121214\n",
      "epoch:  683  -  cost: 0.23845035  -MSE: 135.62322627490028  -Train Accuracy:  0.8848485\n",
      "epoch:  684  -  cost: 0.23703313  -MSE: 139.46789273479374  -Train Accuracy:  0.92121214\n",
      "epoch:  685  -  cost: 0.2373671  -MSE: 135.67684661060397  -Train Accuracy:  0.8848485\n",
      "epoch:  686  -  cost: 0.23531577  -MSE: 139.43536154288458  -Train Accuracy:  0.92121214\n",
      "epoch:  687  -  cost: 0.23548102  -MSE: 135.6192414111682  -Train Accuracy:  0.8848485\n",
      "epoch:  688  -  cost: 0.23526935  -MSE: 139.38844528957293  -Train Accuracy:  0.92121214\n",
      "epoch:  689  -  cost: 0.23639894  -MSE: 135.60632584052158  -Train Accuracy:  0.8848485\n",
      "epoch:  690  -  cost: 0.23551638  -MSE: 139.50572436870107  -Train Accuracy:  0.92121214\n",
      "epoch:  691  -  cost: 0.23526752  -MSE: 135.65684535722127  -Train Accuracy:  0.8848485\n",
      "epoch:  692  -  cost: 0.23304862  -MSE: 139.39234169791865  -Train Accuracy:  0.92121214\n",
      "epoch:  693  -  cost: 0.23390856  -MSE: 135.74176070865002  -Train Accuracy:  0.8848485\n",
      "epoch:  694  -  cost: 0.23224615  -MSE: 139.3526786975587  -Train Accuracy:  0.92121214\n",
      "epoch:  695  -  cost: 0.23138982  -MSE: 135.7309869952435  -Train Accuracy:  0.8848485\n",
      "epoch:  696  -  cost: 0.23003699  -MSE: 139.22959026723262  -Train Accuracy:  0.92121214\n",
      "epoch:  697  -  cost: 0.22925149  -MSE: 136.07669875188532  -Train Accuracy:  0.8909091\n",
      "epoch:  698  -  cost: 0.2273645  -MSE: 139.44546478074977  -Train Accuracy:  0.93333334\n",
      "epoch:  699  -  cost: 0.22642106  -MSE: 135.97314555306676  -Train Accuracy:  0.8909091\n",
      "epoch:  700  -  cost: 0.22553858  -MSE: 139.18848230426397  -Train Accuracy:  0.93333334\n",
      "epoch:  701  -  cost: 0.22504254  -MSE: 136.16131466280535  -Train Accuracy:  0.8848485\n",
      "epoch:  702  -  cost: 0.22507925  -MSE: 139.3555386849534  -Train Accuracy:  0.93333334\n",
      "epoch:  703  -  cost: 0.22407721  -MSE: 136.03789158685464  -Train Accuracy:  0.8969697\n",
      "epoch:  704  -  cost: 0.22319253  -MSE: 139.1802104085815  -Train Accuracy:  0.93333334\n",
      "epoch:  705  -  cost: 0.22241177  -MSE: 136.4389572979596  -Train Accuracy:  0.8848485\n",
      "epoch:  706  -  cost: 0.22150141  -MSE: 139.44562745622213  -Train Accuracy:  0.93333334\n",
      "epoch:  707  -  cost: 0.22066493  -MSE: 136.3649663991175  -Train Accuracy:  0.8909091\n",
      "epoch:  708  -  cost: 0.22077787  -MSE: 139.27797064189716  -Train Accuracy:  0.93939394\n",
      "epoch:  709  -  cost: 0.22034031  -MSE: 136.56816935874906  -Train Accuracy:  0.8909091\n",
      "epoch:  710  -  cost: 0.21902917  -MSE: 139.4508483265227  -Train Accuracy:  0.93333334\n",
      "epoch:  711  -  cost: 0.21836948  -MSE: 136.55720749193634  -Train Accuracy:  0.8909091\n",
      "epoch:  712  -  cost: 0.21823896  -MSE: 139.3164886090098  -Train Accuracy:  0.93333334\n",
      "epoch:  713  -  cost: 0.21752661  -MSE: 136.8742494042097  -Train Accuracy:  0.8909091\n",
      "epoch:  714  -  cost: 0.21736245  -MSE: 139.59881448013797  -Train Accuracy:  0.93333334\n",
      "epoch:  715  -  cost: 0.21708718  -MSE: 136.63723794863566  -Train Accuracy:  0.8909091\n",
      "epoch:  716  -  cost: 0.2173043  -MSE: 139.46472991490032  -Train Accuracy:  0.93333334\n",
      "epoch:  717  -  cost: 0.21673727  -MSE: 137.0132112225922  -Train Accuracy:  0.8909091\n",
      "epoch:  718  -  cost: 0.21581791  -MSE: 139.7403584460565  -Train Accuracy:  0.93939394\n",
      "epoch:  719  -  cost: 0.2157424  -MSE: 136.85201614700335  -Train Accuracy:  0.8969697\n",
      "epoch:  720  -  cost: 0.21592356  -MSE: 139.52086979445713  -Train Accuracy:  0.93939394\n",
      "epoch:  721  -  cost: 0.21543226  -MSE: 137.1037852539552  -Train Accuracy:  0.8909091\n",
      "epoch:  722  -  cost: 0.21449846  -MSE: 139.78880111682278  -Train Accuracy:  0.93939394\n",
      "epoch:  723  -  cost: 0.21454498  -MSE: 136.9381856342526  -Train Accuracy:  0.9030303\n",
      "epoch:  724  -  cost: 0.21491988  -MSE: 139.6485491076656  -Train Accuracy:  0.93939394\n",
      "epoch:  725  -  cost: 0.21441185  -MSE: 137.2255905295496  -Train Accuracy:  0.8909091\n",
      "epoch:  726  -  cost: 0.21432893  -MSE: 139.94775428516576  -Train Accuracy:  0.93939394\n",
      "epoch:  727  -  cost: 0.21376327  -MSE: 137.1939822158942  -Train Accuracy:  0.9030303\n",
      "epoch:  728  -  cost: 0.21386816  -MSE: 139.95643126287226  -Train Accuracy:  0.93939394\n",
      "epoch:  729  -  cost: 0.21340036  -MSE: 137.448852469119  -Train Accuracy:  0.8909091\n",
      "epoch:  730  -  cost: 0.21330592  -MSE: 140.13068300528116  -Train Accuracy:  0.93939394\n",
      "epoch:  731  -  cost: 0.21301891  -MSE: 137.24356085109585  -Train Accuracy:  0.9030303\n",
      "epoch:  732  -  cost: 0.2135232  -MSE: 139.98422005095458  -Train Accuracy:  0.94545454\n",
      "epoch:  733  -  cost: 0.21297422  -MSE: 137.41972063729523  -Train Accuracy:  0.8969697\n",
      "epoch:  734  -  cost: 0.21254021  -MSE: 140.17738591786093  -Train Accuracy:  0.93939394\n",
      "epoch:  735  -  cost: 0.2121639  -MSE: 137.32047522754732  -Train Accuracy:  0.9030303\n",
      "epoch:  736  -  cost: 0.21237765  -MSE: 140.05719583292017  -Train Accuracy:  0.94545454\n",
      "epoch:  737  -  cost: 0.21184552  -MSE: 137.53259189734075  -Train Accuracy:  0.8969697\n",
      "epoch:  738  -  cost: 0.21187253  -MSE: 140.2938933932389  -Train Accuracy:  0.93939394\n",
      "epoch:  739  -  cost: 0.21139091  -MSE: 137.44138164257194  -Train Accuracy:  0.9030303\n",
      "epoch:  740  -  cost: 0.21167871  -MSE: 140.187614982213  -Train Accuracy:  0.94545454\n",
      "epoch:  741  -  cost: 0.21143764  -MSE: 137.61989218565057  -Train Accuracy:  0.8969697\n",
      "epoch:  742  -  cost: 0.21067546  -MSE: 140.35150358484793  -Train Accuracy:  0.93939394\n",
      "epoch:  743  -  cost: 0.20986037  -MSE: 137.7173254231063  -Train Accuracy:  0.9030303\n",
      "epoch:  744  -  cost: 0.21026872  -MSE: 140.38462419307038  -Train Accuracy:  0.94545454\n",
      "epoch:  745  -  cost: 0.2097143  -MSE: 137.81165656750065  -Train Accuracy:  0.9030303\n",
      "epoch:  746  -  cost: 0.20994589  -MSE: 140.50509409081414  -Train Accuracy:  0.93939394\n",
      "epoch:  747  -  cost: 0.20955147  -MSE: 137.664121282852  -Train Accuracy:  0.9030303\n",
      "epoch:  748  -  cost: 0.20927991  -MSE: 140.36538063945173  -Train Accuracy:  0.94545454\n",
      "epoch:  749  -  cost: 0.20875856  -MSE: 137.8907486601943  -Train Accuracy:  0.9030303\n",
      "epoch:  750  -  cost: 0.20847903  -MSE: 140.53483699448165  -Train Accuracy:  0.93939394\n",
      "epoch:  751  -  cost: 0.20777448  -MSE: 137.95385823002982  -Train Accuracy:  0.9030303\n",
      "epoch:  752  -  cost: 0.20798354  -MSE: 140.54063202474356  -Train Accuracy:  0.94545454\n",
      "epoch:  753  -  cost: 0.2074453  -MSE: 138.05533491951627  -Train Accuracy:  0.9030303\n",
      "epoch:  754  -  cost: 0.20683245  -MSE: 140.62045190558854  -Train Accuracy:  0.93939394\n",
      "epoch:  755  -  cost: 0.20654902  -MSE: 137.97744716581124  -Train Accuracy:  0.9030303\n",
      "epoch:  756  -  cost: 0.20670561  -MSE: 140.60497067723853  -Train Accuracy:  0.93939394\n",
      "epoch:  757  -  cost: 0.20585242  -MSE: 138.19327543973756  -Train Accuracy:  0.90909094\n",
      "epoch:  758  -  cost: 0.20595026  -MSE: 140.7172834562813  -Train Accuracy:  0.93939394\n",
      "epoch:  759  -  cost: 0.20563638  -MSE: 138.10020879872067  -Train Accuracy:  0.91515154\n",
      "epoch:  760  -  cost: 0.20573294  -MSE: 140.6992351185358  -Train Accuracy:  0.94545454\n",
      "epoch:  761  -  cost: 0.20481142  -MSE: 138.3550435764984  -Train Accuracy:  0.9030303\n",
      "epoch:  762  -  cost: 0.20459853  -MSE: 140.80404785113976  -Train Accuracy:  0.94545454\n",
      "epoch:  763  -  cost: 0.20428626  -MSE: 138.24039704511407  -Train Accuracy:  0.90909094\n",
      "epoch:  764  -  cost: 0.20476921  -MSE: 140.84367832184512  -Train Accuracy:  0.95151514\n",
      "epoch:  765  -  cost: 0.20408605  -MSE: 138.47673601381462  -Train Accuracy:  0.90909094\n",
      "epoch:  766  -  cost: 0.2043147  -MSE: 141.03946665591482  -Train Accuracy:  0.95151514\n",
      "epoch:  767  -  cost: 0.204421  -MSE: 138.3048159047101  -Train Accuracy:  0.91515154\n",
      "epoch:  768  -  cost: 0.20476583  -MSE: 141.0187210084944  -Train Accuracy:  0.94545454\n",
      "epoch:  769  -  cost: 0.20449455  -MSE: 138.57071292098917  -Train Accuracy:  0.90909094\n",
      "epoch:  770  -  cost: 0.20370165  -MSE: 141.11697923391162  -Train Accuracy:  0.95151514\n",
      "epoch:  771  -  cost: 0.20344795  -MSE: 138.5944361218539  -Train Accuracy:  0.91515154\n",
      "epoch:  772  -  cost: 0.20360532  -MSE: 141.2537100031321  -Train Accuracy:  0.94545454\n",
      "epoch:  773  -  cost: 0.20329155  -MSE: 138.75000172467975  -Train Accuracy:  0.90909094\n",
      "epoch:  774  -  cost: 0.2035589  -MSE: 141.32336268504815  -Train Accuracy:  0.94545454\n",
      "epoch:  775  -  cost: 0.20364884  -MSE: 138.55203359426528  -Train Accuracy:  0.90909094\n",
      "epoch:  776  -  cost: 0.203831  -MSE: 141.31117455291525  -Train Accuracy:  0.94545454\n",
      "epoch:  777  -  cost: 0.20398812  -MSE: 138.60231161653022  -Train Accuracy:  0.90909094\n",
      "epoch:  778  -  cost: 0.20410551  -MSE: 141.416402179416  -Train Accuracy:  0.94545454\n",
      "epoch:  779  -  cost: 0.20381404  -MSE: 138.81668743460912  -Train Accuracy:  0.90909094\n",
      "epoch:  780  -  cost: 0.2034191  -MSE: 141.46526082868172  -Train Accuracy:  0.94545454\n",
      "epoch:  781  -  cost: 0.20339237  -MSE: 138.74668407988568  -Train Accuracy:  0.91515154\n",
      "epoch:  782  -  cost: 0.20334496  -MSE: 141.5273182533101  -Train Accuracy:  0.94545454\n",
      "epoch:  783  -  cost: 0.20325895  -MSE: 138.81269111081298  -Train Accuracy:  0.91515154\n",
      "epoch:  784  -  cost: 0.20366861  -MSE: 141.57250162429517  -Train Accuracy:  0.94545454\n",
      "epoch:  785  -  cost: 0.20386699  -MSE: 138.61610802574606  -Train Accuracy:  0.90909094\n",
      "epoch:  786  -  cost: 0.20438445  -MSE: 141.65824965835273  -Train Accuracy:  0.94545454\n",
      "epoch:  787  -  cost: 0.20424144  -MSE: 138.67123918703834  -Train Accuracy:  0.90909094\n",
      "epoch:  788  -  cost: 0.20412424  -MSE: 141.6682511411432  -Train Accuracy:  0.94545454\n",
      "epoch:  789  -  cost: 0.20359962  -MSE: 138.8803337415497  -Train Accuracy:  0.9030303\n",
      "epoch:  790  -  cost: 0.2028609  -MSE: 141.68925496568767  -Train Accuracy:  0.94545454\n",
      "epoch:  791  -  cost: 0.20301785  -MSE: 138.59113100433098  -Train Accuracy:  0.90909094\n",
      "epoch:  792  -  cost: 0.20327905  -MSE: 141.53110868513116  -Train Accuracy:  0.95151514\n",
      "epoch:  793  -  cost: 0.20268701  -MSE: 138.87044181140104  -Train Accuracy:  0.9030303\n",
      "epoch:  794  -  cost: 0.20196332  -MSE: 141.69761726520593  -Train Accuracy:  0.94545454\n",
      "epoch:  795  -  cost: 0.20180465  -MSE: 138.79898970342106  -Train Accuracy:  0.90909094\n",
      "epoch:  796  -  cost: 0.20165417  -MSE: 141.7053463459344  -Train Accuracy:  0.95151514\n",
      "epoch:  797  -  cost: 0.20111787  -MSE: 139.0022575697232  -Train Accuracy:  0.91515154\n",
      "epoch:  798  -  cost: 0.20052359  -MSE: 141.7572650595438  -Train Accuracy:  0.95757574\n",
      "epoch:  799  -  cost: 0.20064382  -MSE: 138.73744054600488  -Train Accuracy:  0.92121214\n",
      "epoch:  800  -  cost: 0.20038952  -MSE: 141.6082656072524  -Train Accuracy:  0.95757574\n",
      "epoch:  801  -  cost: 0.19973412  -MSE: 139.01399296924177  -Train Accuracy:  0.91515154\n",
      "epoch:  802  -  cost: 0.19919884  -MSE: 141.71761561711153  -Train Accuracy:  0.95757574\n",
      "epoch:  803  -  cost: 0.19911446  -MSE: 138.91551347203583  -Train Accuracy:  0.92121214\n",
      "epoch:  804  -  cost: 0.1990784  -MSE: 141.71767426590378  -Train Accuracy:  0.95757574\n",
      "epoch:  805  -  cost: 0.19859827  -MSE: 139.0940970213541  -Train Accuracy:  0.91515154\n",
      "epoch:  806  -  cost: 0.19875029  -MSE: 141.84835957704112  -Train Accuracy:  0.95757574\n",
      "epoch:  807  -  cost: 0.19821377  -MSE: 139.0239463343267  -Train Accuracy:  0.92121214\n",
      "epoch:  808  -  cost: 0.19824205  -MSE: 141.81086215352818  -Train Accuracy:  0.95757574\n",
      "epoch:  809  -  cost: 0.19776027  -MSE: 139.06284507217566  -Train Accuracy:  0.92121214\n",
      "epoch:  810  -  cost: 0.19727643  -MSE: 141.76859132441496  -Train Accuracy:  0.95757574\n",
      "epoch:  811  -  cost: 0.1971426  -MSE: 139.04162942447303  -Train Accuracy:  0.92121214\n",
      "epoch:  812  -  cost: 0.19727395  -MSE: 141.81639261142143  -Train Accuracy:  0.95757574\n",
      "epoch:  813  -  cost: 0.1972006  -MSE: 138.9232297485868  -Train Accuracy:  0.92121214\n",
      "epoch:  814  -  cost: 0.19655614  -MSE: 141.7383119703421  -Train Accuracy:  0.95757574\n",
      "epoch:  815  -  cost: 0.19631167  -MSE: 139.0721845025901  -Train Accuracy:  0.92121214\n",
      "epoch:  816  -  cost: 0.19654807  -MSE: 141.86430295040506  -Train Accuracy:  0.95757574\n",
      "epoch:  817  -  cost: 0.19658142  -MSE: 139.09248998711942  -Train Accuracy:  0.92121214\n",
      "epoch:  818  -  cost: 0.19652416  -MSE: 141.97645622180056  -Train Accuracy:  0.95757574\n",
      "epoch:  819  -  cost: 0.19619483  -MSE: 138.96638974437033  -Train Accuracy:  0.92121214\n",
      "epoch:  820  -  cost: 0.19672112  -MSE: 141.88277202024014  -Train Accuracy:  0.95757574\n",
      "epoch:  821  -  cost: 0.19657663  -MSE: 139.05291590434413  -Train Accuracy:  0.92121214\n",
      "epoch:  822  -  cost: 0.1961701  -MSE: 142.0098888802848  -Train Accuracy:  0.95757574\n",
      "epoch:  823  -  cost: 0.19555497  -MSE: 139.1068925545259  -Train Accuracy:  0.92121214\n",
      "epoch:  824  -  cost: 0.19614498  -MSE: 142.00260483003757  -Train Accuracy:  0.95757574\n",
      "epoch:  825  -  cost: 0.19594066  -MSE: 139.07292635259535  -Train Accuracy:  0.92121214\n",
      "epoch:  826  -  cost: 0.19626455  -MSE: 142.11451011711347  -Train Accuracy:  0.95757574\n",
      "epoch:  827  -  cost: 0.19605306  -MSE: 138.87370504573965  -Train Accuracy:  0.92121214\n",
      "epoch:  828  -  cost: 0.19654179  -MSE: 141.9323890236121  -Train Accuracy:  0.95757574\n",
      "epoch:  829  -  cost: 0.19580875  -MSE: 139.0842712642268  -Train Accuracy:  0.92121214\n",
      "epoch:  830  -  cost: 0.19546337  -MSE: 142.04259956682696  -Train Accuracy:  0.95757574\n",
      "epoch:  831  -  cost: 0.19551879  -MSE: 138.796371006865  -Train Accuracy:  0.92121214\n",
      "epoch:  832  -  cost: 0.19557308  -MSE: 141.9575716604602  -Train Accuracy:  0.95757574\n",
      "epoch:  833  -  cost: 0.1949506  -MSE: 139.01119478175843  -Train Accuracy:  0.92121214\n",
      "epoch:  834  -  cost: 0.19493672  -MSE: 142.053113566363  -Train Accuracy:  0.95757574\n",
      "epoch:  835  -  cost: 0.19415662  -MSE: 139.08759271006684  -Train Accuracy:  0.92121214\n",
      "epoch:  836  -  cost: 0.19370325  -MSE: 142.0480586503134  -Train Accuracy:  0.95757574\n",
      "epoch:  837  -  cost: 0.19329853  -MSE: 139.1537852066635  -Train Accuracy:  0.92121214\n",
      "epoch:  838  -  cost: 0.19345981  -MSE: 142.12010151639723  -Train Accuracy:  0.95757574\n",
      "epoch:  839  -  cost: 0.19284765  -MSE: 138.9768954845469  -Train Accuracy:  0.92121214\n",
      "epoch:  840  -  cost: 0.19267684  -MSE: 141.96019759562017  -Train Accuracy:  0.95757574\n",
      "epoch:  841  -  cost: 0.19183329  -MSE: 139.23123913998504  -Train Accuracy:  0.92727274\n",
      "epoch:  842  -  cost: 0.19148985  -MSE: 142.05784951873707  -Train Accuracy:  0.95757574\n",
      "epoch:  843  -  cost: 0.19118707  -MSE: 139.120539433463  -Train Accuracy:  0.92727274\n",
      "epoch:  844  -  cost: 0.19127502  -MSE: 142.04826382250866  -Train Accuracy:  0.95757574\n",
      "epoch:  845  -  cost: 0.19038776  -MSE: 139.33738345704032  -Train Accuracy:  0.92727274\n",
      "epoch:  846  -  cost: 0.19037038  -MSE: 142.0912968752591  -Train Accuracy:  0.95757574\n",
      "epoch:  847  -  cost: 0.1900036  -MSE: 139.28084823317766  -Train Accuracy:  0.93333334\n",
      "epoch:  848  -  cost: 0.1903996  -MSE: 142.13910493870762  -Train Accuracy:  0.95757574\n",
      "epoch:  849  -  cost: 0.1908025  -MSE: 139.02558356784132  -Train Accuracy:  0.92727274\n",
      "epoch:  850  -  cost: 0.19105887  -MSE: 142.07568784719092  -Train Accuracy:  0.95757574\n",
      "epoch:  851  -  cost: 0.19068809  -MSE: 139.21255281063327  -Train Accuracy:  0.92121214\n",
      "epoch:  852  -  cost: 0.19108732  -MSE: 142.16706091074843  -Train Accuracy:  0.95757574\n",
      "epoch:  853  -  cost: 0.19026223  -MSE: 139.17255530945093  -Train Accuracy:  0.92727274\n",
      "epoch:  854  -  cost: 0.19041613  -MSE: 142.17450518854955  -Train Accuracy:  0.95757574\n",
      "epoch:  855  -  cost: 0.18978837  -MSE: 139.351388213396  -Train Accuracy:  0.92727274\n",
      "epoch:  856  -  cost: 0.18997793  -MSE: 142.28634420108867  -Train Accuracy:  0.95757574\n",
      "epoch:  857  -  cost: 0.18966173  -MSE: 139.07343688208533  -Train Accuracy:  0.92727274\n",
      "epoch:  858  -  cost: 0.19016898  -MSE: 142.15969100773185  -Train Accuracy:  0.95757574\n",
      "epoch:  859  -  cost: 0.19059281  -MSE: 139.29658511347142  -Train Accuracy:  0.92121214\n",
      "epoch:  860  -  cost: 0.19096343  -MSE: 142.3376478616809  -Train Accuracy:  0.95757574\n",
      "epoch:  861  -  cost: 0.19125585  -MSE: 138.95401222887108  -Train Accuracy:  0.92121214\n",
      "epoch:  862  -  cost: 0.19157377  -MSE: 142.24815173756252  -Train Accuracy:  0.95757574\n",
      "epoch:  863  -  cost: 0.1918892  -MSE: 139.18881683093247  -Train Accuracy:  0.91515154\n",
      "epoch:  864  -  cost: 0.19205223  -MSE: 142.42324555327667  -Train Accuracy:  0.95757574\n",
      "epoch:  865  -  cost: 0.1920266  -MSE: 139.0330816604308  -Train Accuracy:  0.92121214\n",
      "epoch:  866  -  cost: 0.19251868  -MSE: 142.39827742711154  -Train Accuracy:  0.95757574\n",
      "epoch:  867  -  cost: 0.1925129  -MSE: 139.19321105228073  -Train Accuracy:  0.90909094\n",
      "epoch:  868  -  cost: 0.19280282  -MSE: 142.54223896891267  -Train Accuracy:  0.95757574\n",
      "epoch:  869  -  cost: 0.1933611  -MSE: 138.82458026686882  -Train Accuracy:  0.90909094\n",
      "epoch:  870  -  cost: 0.19284739  -MSE: 142.30893369084856  -Train Accuracy:  0.95151514\n",
      "epoch:  871  -  cost: 0.19254446  -MSE: 139.0956014569732  -Train Accuracy:  0.90909094\n",
      "epoch:  872  -  cost: 0.19247246  -MSE: 142.458514280237  -Train Accuracy:  0.95151514\n",
      "epoch:  873  -  cost: 0.19240616  -MSE: 138.96310131151046  -Train Accuracy:  0.90909094\n",
      "epoch:  874  -  cost: 0.1919608  -MSE: 142.41692805832827  -Train Accuracy:  0.95151514\n",
      "epoch:  875  -  cost: 0.1924935  -MSE: 138.9891647122159  -Train Accuracy:  0.90909094\n",
      "epoch:  876  -  cost: 0.19211818  -MSE: 142.47624395145917  -Train Accuracy:  0.95151514\n",
      "epoch:  877  -  cost: 0.19208303  -MSE: 138.80935307330384  -Train Accuracy:  0.8969697\n",
      "epoch:  878  -  cost: 0.19157106  -MSE: 142.19310949550035  -Train Accuracy:  0.95151514\n",
      "epoch:  879  -  cost: 0.19130939  -MSE: 138.83197709384197  -Train Accuracy:  0.90909094\n",
      "epoch:  880  -  cost: 0.19037476  -MSE: 142.2012553565599  -Train Accuracy:  0.95757574\n",
      "epoch:  881  -  cost: 0.18924889  -MSE: 138.75648991756654  -Train Accuracy:  0.90909094\n",
      "epoch:  882  -  cost: 0.1886397  -MSE: 142.0346362257154  -Train Accuracy:  0.95757574\n",
      "epoch:  883  -  cost: 0.18777817  -MSE: 138.77218862620515  -Train Accuracy:  0.91515154\n",
      "epoch:  884  -  cost: 0.18665446  -MSE: 141.97631313748013  -Train Accuracy:  0.96363634\n",
      "epoch:  885  -  cost: 0.1859034  -MSE: 138.8313841374829  -Train Accuracy:  0.92727274\n",
      "epoch:  886  -  cost: 0.18404777  -MSE: 141.9376570619366  -Train Accuracy:  0.96363634\n",
      "epoch:  887  -  cost: 0.18382768  -MSE: 139.00472143960718  -Train Accuracy:  0.93333334\n",
      "epoch:  888  -  cost: 0.18329984  -MSE: 141.96291896418902  -Train Accuracy:  0.96363634\n",
      "epoch:  889  -  cost: 0.1822971  -MSE: 139.23687913369733  -Train Accuracy:  0.93939394\n",
      "epoch:  890  -  cost: 0.18254119  -MSE: 142.0260976169412  -Train Accuracy:  0.969697\n",
      "epoch:  891  -  cost: 0.18232074  -MSE: 139.11928564600962  -Train Accuracy:  0.93333334\n",
      "epoch:  892  -  cost: 0.18146254  -MSE: 142.01935484046038  -Train Accuracy:  0.969697\n",
      "epoch:  893  -  cost: 0.180862  -MSE: 139.33431536069284  -Train Accuracy:  0.93333334\n",
      "epoch:  894  -  cost: 0.18099624  -MSE: 142.05619947397705  -Train Accuracy:  0.969697\n",
      "epoch:  895  -  cost: 0.18028143  -MSE: 139.30320014676886  -Train Accuracy:  0.93333334\n",
      "epoch:  896  -  cost: 0.1794444  -MSE: 142.04677083893213  -Train Accuracy:  0.969697\n",
      "epoch:  897  -  cost: 0.17920183  -MSE: 139.4073851058246  -Train Accuracy:  0.92727274\n",
      "epoch:  898  -  cost: 0.17933883  -MSE: 142.04439107123224  -Train Accuracy:  0.969697\n",
      "epoch:  899  -  cost: 0.17886789  -MSE: 139.295002341819  -Train Accuracy:  0.93333334\n",
      "epoch:  900  -  cost: 0.17931582  -MSE: 141.9626190191491  -Train Accuracy:  0.969697\n",
      "epoch:  901  -  cost: 0.17998973  -MSE: 139.1502431401405  -Train Accuracy:  0.93333334\n",
      "epoch:  902  -  cost: 0.18017949  -MSE: 142.0603401743288  -Train Accuracy:  0.96363634\n",
      "epoch:  903  -  cost: 0.18009038  -MSE: 139.32120013113737  -Train Accuracy:  0.93333334\n",
      "epoch:  904  -  cost: 0.18094802  -MSE: 142.11357976773175  -Train Accuracy:  0.96363634\n",
      "epoch:  905  -  cost: 0.18099026  -MSE: 139.299968210199  -Train Accuracy:  0.92121214\n",
      "epoch:  906  -  cost: 0.18120146  -MSE: 142.24976952649797  -Train Accuracy:  0.96363634\n",
      "epoch:  907  -  cost: 0.18132444  -MSE: 139.08345130325472  -Train Accuracy:  0.90909094\n",
      "epoch:  908  -  cost: 0.18220316  -MSE: 142.21208318250254  -Train Accuracy:  0.96363634\n",
      "epoch:  909  -  cost: 0.18239662  -MSE: 139.17772838681046  -Train Accuracy:  0.91515154\n",
      "epoch:  910  -  cost: 0.18262216  -MSE: 142.28128760341406  -Train Accuracy:  0.96363634\n",
      "epoch:  911  -  cost: 0.18250455  -MSE: 138.8340170692762  -Train Accuracy:  0.90909094\n",
      "epoch:  912  -  cost: 0.18291336  -MSE: 142.07580345857787  -Train Accuracy:  0.95757574\n",
      "epoch:  913  -  cost: 0.18304427  -MSE: 138.95531767501683  -Train Accuracy:  0.9030303\n",
      "epoch:  914  -  cost: 0.18267092  -MSE: 142.21168732185902  -Train Accuracy:  0.95757574\n",
      "epoch:  915  -  cost: 0.18285766  -MSE: 138.699365221599  -Train Accuracy:  0.90909094\n",
      "epoch:  916  -  cost: 0.1819631  -MSE: 142.02383030907208  -Train Accuracy:  0.95757574\n",
      "epoch:  917  -  cost: 0.1824705  -MSE: 138.7919631612552  -Train Accuracy:  0.9030303\n",
      "epoch:  918  -  cost: 0.18268867  -MSE: 142.08426519368732  -Train Accuracy:  0.95757574\n",
      "epoch:  919  -  cost: 0.18213786  -MSE: 138.67512753216903  -Train Accuracy:  0.9030303\n",
      "epoch:  920  -  cost: 0.18115792  -MSE: 141.999752069797  -Train Accuracy:  0.95757574\n",
      "epoch:  921  -  cost: 0.18166767  -MSE: 138.63189075714763  -Train Accuracy:  0.90909094\n",
      "epoch:  922  -  cost: 0.1800557  -MSE: 141.94824811305946  -Train Accuracy:  0.96363634\n",
      "epoch:  923  -  cost: 0.17925988  -MSE: 138.71354774695126  -Train Accuracy:  0.90909094\n",
      "epoch:  924  -  cost: 0.17785366  -MSE: 141.84536111279962  -Train Accuracy:  0.96363634\n",
      "epoch:  925  -  cost: 0.17739706  -MSE: 138.9042190899632  -Train Accuracy:  0.92121214\n",
      "epoch:  926  -  cost: 0.1760847  -MSE: 141.85556871137152  -Train Accuracy:  0.969697\n",
      "epoch:  927  -  cost: 0.17580195  -MSE: 138.6268613308884  -Train Accuracy:  0.92121214\n",
      "epoch:  928  -  cost: 0.17446005  -MSE: 141.6880065764589  -Train Accuracy:  0.969697\n",
      "epoch:  929  -  cost: 0.17386125  -MSE: 139.10432671438662  -Train Accuracy:  0.92121214\n",
      "epoch:  930  -  cost: 0.1731849  -MSE: 141.85315681286986  -Train Accuracy:  0.969697\n",
      "epoch:  931  -  cost: 0.1728504  -MSE: 139.08226555926353  -Train Accuracy:  0.92727274\n",
      "epoch:  932  -  cost: 0.1714888  -MSE: 141.8613301125942  -Train Accuracy:  0.969697\n",
      "epoch:  933  -  cost: 0.17111628  -MSE: 139.25128666711186  -Train Accuracy:  0.93333334\n",
      "epoch:  934  -  cost: 0.16998227  -MSE: 141.89638393731664  -Train Accuracy:  0.9757576\n",
      "epoch:  935  -  cost: 0.1697607  -MSE: 139.37087732534772  -Train Accuracy:  0.93939394\n",
      "epoch:  936  -  cost: 0.16877852  -MSE: 141.8951974037653  -Train Accuracy:  0.9757576\n",
      "epoch:  937  -  cost: 0.16894427  -MSE: 139.46935839073905  -Train Accuracy:  0.93939394\n",
      "epoch:  938  -  cost: 0.16725303  -MSE: 141.9271806072192  -Train Accuracy:  0.9757576\n",
      "epoch:  939  -  cost: 0.16711783  -MSE: 139.41943980739728  -Train Accuracy:  0.93939394\n",
      "epoch:  940  -  cost: 0.1656366  -MSE: 141.78250910776595  -Train Accuracy:  0.9757576\n",
      "epoch:  941  -  cost: 0.16541192  -MSE: 139.87218386697518  -Train Accuracy:  0.93939394\n",
      "epoch:  942  -  cost: 0.16409118  -MSE: 141.8971385167309  -Train Accuracy:  0.9757576\n",
      "epoch:  943  -  cost: 0.1635792  -MSE: 139.90377338042722  -Train Accuracy:  0.93939394\n",
      "epoch:  944  -  cost: 0.16244349  -MSE: 141.8692925251678  -Train Accuracy:  0.9757576\n",
      "epoch:  945  -  cost: 0.16216862  -MSE: 140.20853874946494  -Train Accuracy:  0.94545454\n",
      "epoch:  946  -  cost: 0.16127403  -MSE: 141.92898518211544  -Train Accuracy:  0.9757576\n",
      "epoch:  947  -  cost: 0.16084209  -MSE: 140.319614763644  -Train Accuracy:  0.95151514\n",
      "epoch:  948  -  cost: 0.16009267  -MSE: 141.94392981526636  -Train Accuracy:  0.9757576\n",
      "epoch:  949  -  cost: 0.15984482  -MSE: 140.46915481398588  -Train Accuracy:  0.95151514\n",
      "epoch:  950  -  cost: 0.15927625  -MSE: 141.98671620054074  -Train Accuracy:  0.9757576\n",
      "epoch:  951  -  cost: 0.15902011  -MSE: 140.5729898832958  -Train Accuracy:  0.95757574\n",
      "epoch:  952  -  cost: 0.15823166  -MSE: 141.98962956447141  -Train Accuracy:  0.9757576\n",
      "epoch:  953  -  cost: 0.1577535  -MSE: 140.94412276921065  -Train Accuracy:  0.95757574\n",
      "epoch:  954  -  cost: 0.15732978  -MSE: 142.0802229117922  -Train Accuracy:  0.9757576\n",
      "epoch:  955  -  cost: 0.1573899  -MSE: 140.7051223758646  -Train Accuracy:  0.96363634\n",
      "epoch:  956  -  cost: 0.15686756  -MSE: 142.04136861482937  -Train Accuracy:  0.9757576\n",
      "epoch:  957  -  cost: 0.15681612  -MSE: 141.19809522161  -Train Accuracy:  0.96363634\n",
      "epoch:  958  -  cost: 0.15625745  -MSE: 142.28413171945292  -Train Accuracy:  0.9757576\n",
      "epoch:  959  -  cost: 0.1562975  -MSE: 140.98657944252386  -Train Accuracy:  0.96363634\n",
      "epoch:  960  -  cost: 0.15597968  -MSE: 142.25340648297092  -Train Accuracy:  0.9757576\n",
      "epoch:  961  -  cost: 0.1556776  -MSE: 141.46728351705283  -Train Accuracy:  0.96363634\n",
      "epoch:  962  -  cost: 0.1555786  -MSE: 142.56204655535947  -Train Accuracy:  0.9757576\n",
      "epoch:  963  -  cost: 0.15580171  -MSE: 141.20773422337194  -Train Accuracy:  0.96363634\n",
      "epoch:  964  -  cost: 0.15559593  -MSE: 142.57459104986347  -Train Accuracy:  0.9757576\n",
      "epoch:  965  -  cost: 0.15590675  -MSE: 141.43472060931978  -Train Accuracy:  0.96363634\n",
      "epoch:  966  -  cost: 0.15565483  -MSE: 142.77968945365646  -Train Accuracy:  0.9757576\n",
      "epoch:  967  -  cost: 0.15573971  -MSE: 141.38168968777003  -Train Accuracy:  0.96363634\n",
      "epoch:  968  -  cost: 0.15564029  -MSE: 142.8216701068398  -Train Accuracy:  0.9757576\n",
      "epoch:  969  -  cost: 0.15587524  -MSE: 141.45909500793326  -Train Accuracy:  0.96363634\n",
      "epoch:  970  -  cost: 0.15564226  -MSE: 142.94289095198846  -Train Accuracy:  0.9757576\n",
      "epoch:  971  -  cost: 0.15573117  -MSE: 141.41277594485558  -Train Accuracy:  0.95757574\n",
      "epoch:  972  -  cost: 0.15563115  -MSE: 143.02273414384598  -Train Accuracy:  0.9757576\n",
      "epoch:  973  -  cost: 0.15591985  -MSE: 141.49347248382466  -Train Accuracy:  0.95757574\n",
      "epoch:  974  -  cost: 0.15578401  -MSE: 143.11863884633587  -Train Accuracy:  0.9757576\n",
      "epoch:  975  -  cost: 0.15620337  -MSE: 141.2718167238988  -Train Accuracy:  0.95757574\n",
      "epoch:  976  -  cost: 0.15639076  -MSE: 143.3161288298666  -Train Accuracy:  0.9757576\n",
      "epoch:  977  -  cost: 0.1574079  -MSE: 141.11430144940854  -Train Accuracy:  0.95151514\n",
      "epoch:  978  -  cost: 0.15755728  -MSE: 143.34394990817088  -Train Accuracy:  0.9757576\n",
      "epoch:  979  -  cost: 0.15828066  -MSE: 141.18156391624544  -Train Accuracy:  0.94545454\n",
      "epoch:  980  -  cost: 0.15987188  -MSE: 143.45890833589257  -Train Accuracy:  0.9757576\n",
      "epoch:  981  -  cost: 0.16142873  -MSE: 140.92061277793013  -Train Accuracy:  0.93939394\n",
      "epoch:  982  -  cost: 0.1640248  -MSE: 143.66485489549498  -Train Accuracy:  0.969697\n",
      "epoch:  983  -  cost: 0.16638753  -MSE: 140.37096898810992  -Train Accuracy:  0.92727274\n",
      "epoch:  984  -  cost: 0.16732405  -MSE: 143.42318279838474  -Train Accuracy:  0.969697\n",
      "epoch:  985  -  cost: 0.16927113  -MSE: 139.97404220152853  -Train Accuracy:  0.92727274\n",
      "epoch:  986  -  cost: 0.16983403  -MSE: 143.28247249967058  -Train Accuracy:  0.969697\n",
      "epoch:  987  -  cost: 0.17157578  -MSE: 139.71509760787754  -Train Accuracy:  0.91515154\n",
      "epoch:  988  -  cost: 0.17271703  -MSE: 143.18352726948083  -Train Accuracy:  0.96363634\n",
      "epoch:  989  -  cost: 0.17527147  -MSE: 139.35263216513655  -Train Accuracy:  0.9030303\n",
      "epoch:  990  -  cost: 0.176033  -MSE: 143.13663771145497  -Train Accuracy:  0.95757574\n",
      "epoch:  991  -  cost: 0.17801242  -MSE: 138.93947757631702  -Train Accuracy:  0.9030303\n",
      "epoch:  992  -  cost: 0.17834954  -MSE: 142.90986096391794  -Train Accuracy:  0.95151514\n",
      "epoch:  993  -  cost: 0.18116581  -MSE: 138.77532496222278  -Train Accuracy:  0.9030303\n",
      "epoch:  994  -  cost: 0.1821599  -MSE: 142.97722998617084  -Train Accuracy:  0.95151514\n",
      "epoch:  995  -  cost: 0.18481742  -MSE: 138.12042070954698  -Train Accuracy:  0.8969697\n",
      "epoch:  996  -  cost: 0.18466842  -MSE: 142.49023788932064  -Train Accuracy:  0.95151514\n",
      "epoch:  997  -  cost: 0.18628645  -MSE: 138.1568706685931  -Train Accuracy:  0.8969697\n",
      "epoch:  998  -  cost: 0.18484597  -MSE: 142.54142607987708  -Train Accuracy:  0.95151514\n",
      "epoch:  999  -  cost: 0.18709521  -MSE: 137.55854847710634  -Train Accuracy:  0.8969697\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(training_epochs):\n",
    "    sess.run(training_step, feed_dict={x:train_x, y_true:train_y})\n",
    "    cost = sess.run(cost_function, feed_dict={x:train_x, y_true:train_y})\n",
    "    cost_history = np.append(cost_history, cost)\n",
    "    correct_prediction = tf.equal(tf.argmax(y,1),tf.argmax(y_true,1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction,tf.float32))\n",
    "    \n",
    "    pred_y = sess.run(y,feed_dict={x:test_x})\n",
    "    mse = tf.reduce_mean(tf.square(pred_y - test_y))\n",
    "    mse_ = sess.run(mse)\n",
    "    mse_history.append(mse_)\n",
    "    accuracy = sess.run(accuracy,feed_dict={x: train_x, y_true:train_y})\n",
    "    accuracy_history.append(accuracy)\n",
    "    \n",
    "    print('epoch: ',epoch,' - ','cost:',cost,' -MSE:',mse_,\" -Train Accuracy: \",accuracy)\n",
    "save_path = saver.save(sess, model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy:  0.85714287\n",
      "MSE: 137.5585\n"
     ]
    }
   ],
   "source": [
    "# Plot MSE and accuracy graph\n",
    "plt.title(\"MSE\")\n",
    "plt.plot(mse_history,'r')\n",
    "plt.show()\n",
    "plt.title(\"Accuracy\")\n",
    "plt.plot(accuracy_history)\n",
    "plt.show()\n",
    "    \n",
    "# Print the final accuracy\n",
    "correct_prediction = tf.equal(tf.argmax(y,1),tf.argmax(y_true,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction,tf.float32))\n",
    "print(\"Test Accuracy: \",(sess.run(accuracy, feed_dict={x:test_x, y_true:test_y})))\n",
    "\n",
    "# Print final MSE\n",
    "pred_y = sess.run(y, feed_dict={x:test_x})\n",
    "mse = tf.reduce_mean(tf.square(pred_y-test_y))\n",
    "print(\"MSE: %.4f\"%sess.run(mse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
